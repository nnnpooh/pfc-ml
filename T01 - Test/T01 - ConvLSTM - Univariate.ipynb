{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network - Univariate\n",
    "- Simple RNN\n",
    "- LSTM\n",
    "- GRU\n",
    "- https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to use LSTM and GRU, you need to downgrade numpy\n",
    "- `conda create --name tf tensorflow=2.4`\n",
    "- `conda activate tf`\n",
    "- `conda install numpy=1.19`\n",
    "- `conda install jupyterlab matplotlib pandas`\n",
    "- https://stackoverflow.com/questions/66207609/notimplementederror-cannot-convert-a-symbolic-tensor-lstm-2-strided-slice0-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1-Time1</th>\n",
       "      <th>X1-Time2</th>\n",
       "      <th>X1-Time3</th>\n",
       "      <th>X1-Time4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1-Time1  X1-Time2  X1-Time3  X1-Time4   y\n",
       "sample                                            \n",
       "0             10        20        30        40  50\n",
       "1             20        30        40        50  60\n",
       "2             30        40        50        60  70\n",
       "3             40        50        60        70  80\n",
       "4             50        60        70        80  90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split into samples\n",
    "X_, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# visualize input\n",
    "temp = pd.DataFrame(data=X_, columns=['X1-Time1','X1-Time2','X1-Time3','X1-Time4'])\n",
    "temp['y'] = y\n",
    "temp.index.name='sample'\n",
    "display(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_steps = 2\n",
    "X = X_.reshape((X_.shape[0], n_seq, 1, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, SimpleRNN, GRU, Conv1D, MaxPooling1D, Flatten, ConvLSTM2D\n",
    "\n",
    "def createModel(type):\n",
    "    inputLayer = Input(shape=(n_seq, 1, n_steps, n_features))\n",
    "\n",
    "    if (type == 'ConvLSTM'):\n",
    "        layer = ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu')(inputLayer)\n",
    "        layer = Flatten()(layer)\n",
    "    \n",
    "    outputLayer = Dense(1)(layer)\n",
    "    model = Model(inputs=inputLayer, outputs=outputLayer, name=type)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 05:47:20.722763: I external/local_xla/xla/service/service.cc:168] XLA service 0x555578f4b280 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-03 05:47:20.722817: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-12-03 05:47:20.723400: E external/local_xla/xla/stream_executor/stream_executor_internal.h:177] SetPriority unimplemented for this stream.\n",
      "2023-12-03 05:47:20.723656: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 05:47:20.723700: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 05:47:20.723724: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 05:47:21.115877: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 05:47:21.115936: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 05:47:21.115943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-03 05:47:21.115978: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-03 05:47:21.116000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6109 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:09:00.0, compute capability: 7.5\n",
      "2023-12-03 05:47:21.118559: I external/local_xla/xla/service/service.cc:168] XLA service 0x555579806730 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-03 05:47:21.118574: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ConvLSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2, 1, 2, 1)]      0         \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, 1, 1, 64)          33536     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33601 (131.25 KB)\n",
      "Trainable params: 33601 (131.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 05:47:21.520535: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Model building\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(1)\n",
    "# For somereason if I don't include this, I cannot execute this cell twice for LSTM and GRU\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "\n",
    "ConvLSTM = createModel('ConvLSTM')\n",
    "\n",
    "ConvLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def runModel(model, X, y, **kwargs):\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    if 'learning_rate' in kwargs:\n",
    "        learning_rate = kwargs['learning_rate']\n",
    "\n",
    "    patience = 10\n",
    "    if 'patience' in kwargs:\n",
    "        patience = kwargs['patience']\n",
    "\n",
    "    epochs=200\n",
    "    if 'epochs' in kwargs:\n",
    "        epochs = kwargs['epochs']\n",
    "\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    earlyStoppingCallback = EarlyStopping(monitor='loss', patience=patience, min_delta=0)\n",
    "\n",
    "    history = model.fit(X, y, epochs=epochs, verbose=1, callbacks=[earlyStoppingCallback ])\n",
    "\n",
    "    hist = history.history\n",
    "    x_arr = np.arange(len(hist['loss'])) + 1\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(x_arr, hist['loss'], '-o', label='Train loss')\n",
    "    ax.set_xlabel('Epoch', size=15)\n",
    "    ax.set_ylabel('Loss', size=15)\n",
    "    ax.legend(fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 05:47:23.032238: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2023-12-03 05:47:23.290361: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-03 05:47:24.356667: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1701557244.440885    1836 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 4938.7881\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4818.4326\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4701.7788\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4589.4443\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4479.4111\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4366.0933\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4254.0410\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4146.6494\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4038.7891\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3930.8965\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3821.5493\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3709.7876\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3597.1008\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3486.7024\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3374.0891\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3262.0923\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3146.4875\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3027.7310\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2905.0225\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2781.9985\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2653.5842\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2524.8613\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2395.7104\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2267.6445\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2145.7258\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2025.7115\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1904.8785\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1784.4922\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1662.5574\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1537.5762\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1415.1096\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1298.6034\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1183.9447\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1073.4761\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 967.2877\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 864.0527\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 760.9659\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 661.1796\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 566.3193\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 477.1012\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 396.2520\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 326.0538\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 266.4660\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 214.1356\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 171.0777\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 137.7491\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 113.9469\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 100.4944\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 96.9683\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 101.9906\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 110.8214\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 119.3371\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 124.5765\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 125.3655\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 120.9541\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 114.4167\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 106.6006\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 97.6769\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 88.7062\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 80.4097\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 73.0408\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 66.7414\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 61.1265\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 56.1057\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 51.8076\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 48.0862\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 44.6035\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 41.6222\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 38.6090\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 35.7126\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 33.0581\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 30.7296\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 28.4501\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 26.2430\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 24.3853\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 22.7364\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 21.2482\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 19.8084\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 18.4085\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 17.1926\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 16.0471\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 14.9891\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 14.0028\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 13.0803\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 12.2302\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 11.4320\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 10.6852\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.9857\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 9.3264\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.6975\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.1331\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6394\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.1691\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.7186\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.2870\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.8767\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.4912\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.1288\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.8007\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5133\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.2504\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.0121\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7904\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.5782\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.3748\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.1864\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.0131\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.8538\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.7006\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.5533\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.4109\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2736\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.1420\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0156\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.8920\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7723\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6626\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5574\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4569\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3655\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2779\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1928\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1108\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0329\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9716\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9209\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8692\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8149\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7589\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7033\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6497\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5983\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5476\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5005\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4633\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4280\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3944\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3617\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3301\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3003\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2733\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2488\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2259\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2037\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1824\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1626\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1450\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1293\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1145\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1011\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0899\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0798\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0714\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0629\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0544\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0466\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0400\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0340\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0290\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0248\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0211\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0180\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0153\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0128\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0104\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0084\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0067\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0053\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0043\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0033\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0025\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0018\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0013\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.7830e-04\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.0236e-04\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.2759e-04\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.2019e-04\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.2645e-04\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2845e-04\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.3873e-05\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.7518e-05\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4738e-05\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.1597e-05\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.6649e-05\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7359e-05\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.9206e-05\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.3247e-05\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1932e-04\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3159e-04\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4166e-04\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5885e-04\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7750e-04\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.8625e-04\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.8387e-04\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.7888e-04\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7726e-04\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.7527e-04\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6708e-04\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5305e-04\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3886e-04\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2770e-04\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1683e-04\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0302e-04\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.7463e-05\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.3842e-05\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.3359e-05\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.3923e-05\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.3730e-05\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.3807e-05\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.6153e-05\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.0831e-05\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6178e-05\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.1340e-05\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.1989e-06\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.7361e-06\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5455e-06\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.5360e-06\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3670e-06\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.5895e-07\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 8.0545e-07\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3384e-06\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.6176e-06\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6693e-06\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9453e-06\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.5684e-06\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.1379e-06\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.3830e-06\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.4566e-06\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.6402e-06\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8972e-06\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9657e-06\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.8196e-06\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.6166e-06\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.4902e-06\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.3763e-06\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.1329e-06\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.7961e-06\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.4975e-06\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2748e-06\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.0239e-06\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7289e-06\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4268e-06\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1981e-06\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0223e-06\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.4004e-07\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.4572e-07\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.8938e-07\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.8698e-07\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.0605e-07\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.2009e-07\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4100e-07\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.5766e-08\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.8115e-08\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.2952e-08\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.2532e-08\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.1298e-08\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.9389e-08\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1671e-08\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.5603e-08\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.5126e-08\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.2626e-08\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.5196e-08\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.2984e-08\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 8.4931e-08\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.6243e-08\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.0411e-08\n",
      "Epoch 267/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.3348e-08\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.9820e-08\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.4081e-08\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.0821e-08\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.7800e-08\n",
      "Epoch 272/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.2707e-08\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.4369e-08\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.7838e-08\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.1089e-08\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.5152e-08\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7710e-08\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.1322e-08\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.6301e-08\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1822e-08\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7043e-08\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2974e-08\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.3045e-09\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.3022e-09\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6694e-09\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.6613e-09\n",
      "Epoch 287/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9587e-09\n",
      "Epoch 288/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.6240e-09\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3562e-09\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.7207e-10\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.3155e-10\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.8685e-10\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1758e-09\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4930e-09\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.6473e-09\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.7695e-09\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.0984e-09\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.2294e-09\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4476e-09\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2381e-09\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.4709e-09\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.6455e-09\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.5670e-09\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3458e-09\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.2032e-09\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.9965e-09\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9005e-09\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5425e-09\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.5280e-09\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3883e-09\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1234e-09\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.4110e-10\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.3633e-10\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.3155e-10\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.6170e-10\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.8522e-10\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.2410e-10\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.8044e-10\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5716e-10\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2760e-11\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.0745e-11\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.9104e-11\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.0745e-11\n",
      "Epoch 324/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.0745e-11\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.7462e-11\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.2387e-11\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.2387e-11\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.5670e-11\n",
      "Epoch 329/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.2760e-11\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.6043e-11\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.9849e-11\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.8953e-11\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.5670e-11\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3388e-10\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3388e-10\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2224e-10\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0768e-10\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.1118e-11\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.2760e-11\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2760e-11\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.2760e-11\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.2387e-11\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.6566e-11\n",
      "Epoch 344/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 8.1491e-11\n",
      "Epoch 345/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.1118e-11\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.7835e-11\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.7835e-11\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.6566e-11\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7835e-11\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.0745e-11\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.4028e-11\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.1118e-11\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4552e-11\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.0745e-11\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.4028e-11\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7462e-11\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.6193e-11\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.9104e-11\n",
      "Epoch 359/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.4925e-11\n",
      "Epoch 360/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3283e-11\n",
      "Epoch 361/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7462e-11\n",
      "Epoch 362/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.4925e-11\n",
      "Epoch 363/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.4925e-11\n",
      "Epoch 364/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.4925e-11\n",
      "Epoch 365/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.9104e-11\n",
      "Epoch 366/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.7835e-11\n",
      "Epoch 367/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.7835e-11\n",
      "Epoch 368/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.6193e-11\n",
      "Epoch 369/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.4925e-11\n",
      "Epoch 370/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.4925e-11\n",
      "Epoch 371/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.7462e-11\n",
      "Epoch 372/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7462e-11\n",
      "Epoch 373/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.9104e-11\n",
      "Epoch 374/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.9104e-11\n",
      "Epoch 375/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.6193e-11\n",
      "Epoch 376/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.7462e-11\n",
      "Epoch 377/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.2387e-11\n",
      "Epoch 378/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.2387e-11\n",
      "Epoch 379/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4552e-11\n",
      "Epoch 380/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.4552e-11\n",
      "Epoch 381/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.1118e-11\n",
      "Epoch 382/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.2387e-11\n",
      "Epoch 383/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.6193e-11\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runModel(ConvLSTM, X, y, learning_rate=0.001, epochs=2000, patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictValue(model, X_):\n",
    "    X = X_.reshape((1, n_seq, 1, n_steps, n_features))\n",
    "    yhat_ = model.predict(X, verbose=0)\n",
    "    yhat = yhat_.flatten()[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM: 103.394\n"
     ]
    }
   ],
   "source": [
    "X_ = np.array([60, 70, 80, 90])\n",
    "print(f\"ConvLSTM: {predictValue(ConvLSTM, X_):5.3f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "183983f8581d242f392f04aa55828dc2781ebbbbdf8bf6ac72073cf044539615"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
