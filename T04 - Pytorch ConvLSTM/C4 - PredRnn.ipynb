{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatioTemporalLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channel, num_hidden, width, filter_size, stride, layer_norm):\n",
    "        super(SpatioTemporalLSTMCell, self).__init__()\n",
    "\n",
    "        self.num_hidden = num_hidden\n",
    "        self.padding = filter_size // 2\n",
    "        self._forget_bias = 1.0\n",
    "        if layer_norm:\n",
    "            self.conv_x = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channel,\n",
    "                    num_hidden * 7,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.LayerNorm([num_hidden * 7, width, width]),\n",
    "            )\n",
    "            self.conv_h = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden,\n",
    "                    num_hidden * 4,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.LayerNorm([num_hidden * 4, width, width]),\n",
    "            )\n",
    "            self.conv_m = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden,\n",
    "                    num_hidden * 3,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.LayerNorm([num_hidden * 3, width, width]),\n",
    "            )\n",
    "            self.conv_o = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden * 2,\n",
    "                    num_hidden,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.LayerNorm([num_hidden, width, width]),\n",
    "            )\n",
    "        else:\n",
    "            self.conv_x = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channel,\n",
    "                    num_hidden * 7,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "            self.conv_h = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden,\n",
    "                    num_hidden * 4,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "            self.conv_m = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden,\n",
    "                    num_hidden * 3,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "            self.conv_o = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden * 2,\n",
    "                    num_hidden,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "        self.conv_last = nn.Conv2d(\n",
    "            num_hidden * 2, num_hidden, kernel_size=1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x_t, h_t, c_t, m_t):\n",
    "        x_concat = self.conv_x(x_t)\n",
    "        h_concat = self.conv_h(h_t)\n",
    "        m_concat = self.conv_m(m_t)\n",
    "        i_x, f_x, g_x, i_x_prime, f_x_prime, g_x_prime, o_x = torch.split(\n",
    "            x_concat, self.num_hidden, dim=1\n",
    "        )\n",
    "        i_h, f_h, g_h, o_h = torch.split(h_concat, self.num_hidden, dim=1)\n",
    "        i_m, f_m, g_m = torch.split(m_concat, self.num_hidden, dim=1)\n",
    "\n",
    "        i_t = torch.sigmoid(i_x + i_h)\n",
    "        f_t = torch.sigmoid(f_x + f_h + self._forget_bias)\n",
    "        g_t = torch.tanh(g_x + g_h)\n",
    "\n",
    "        c_new = f_t * c_t + i_t * g_t\n",
    "\n",
    "        i_t_prime = torch.sigmoid(i_x_prime + i_m)\n",
    "        f_t_prime = torch.sigmoid(f_x_prime + f_m + self._forget_bias)\n",
    "        g_t_prime = torch.tanh(g_x_prime + g_m)\n",
    "\n",
    "        m_new = f_t_prime * m_t + i_t_prime * g_t_prime\n",
    "\n",
    "        mem = torch.cat((c_new, m_new), 1)\n",
    "        o_t = torch.sigmoid(o_x + o_h + self.conv_o(mem))\n",
    "        h_new = o_t * torch.tanh(self.conv_last(mem))\n",
    "\n",
    "        return h_new, c_new, m_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_layers, num_hidden, configs):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.configs = configs\n",
    "        self.frame_channel = (\n",
    "            configs.patch_size * configs.patch_size * configs.img_channel\n",
    "        )\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        cell_list = []\n",
    "\n",
    "        width = configs.img_width // configs.patch_size\n",
    "        self.MSE_criterion = nn.MSELoss()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            in_channel = self.frame_channel if i == 0 else num_hidden[i - 1]\n",
    "            cell_list.append(\n",
    "                SpatioTemporalLSTMCell(\n",
    "                    in_channel,\n",
    "                    num_hidden[i],\n",
    "                    width,\n",
    "                    configs.filter_size,\n",
    "                    configs.stride,\n",
    "                    configs.layer_norm,\n",
    "                )\n",
    "            )\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "        self.conv_last = nn.Conv2d(\n",
    "            num_hidden[num_layers - 1],\n",
    "            self.frame_channel,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, frames_tensor, mask_true):\n",
    "        # [batch, length, height, width, channel] -> [batch, length, channel, height, width]\n",
    "        frames = frames_tensor.permute(0, 1, 4, 2, 3).contiguous()\n",
    "        mask_true = mask_true.permute(0, 1, 4, 2, 3).contiguous()\n",
    "\n",
    "        batch = frames.shape[0]\n",
    "        height = frames.shape[3]\n",
    "        width = frames.shape[4]\n",
    "\n",
    "        next_frames = []\n",
    "        h_t = []\n",
    "        c_t = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            zeros = torch.zeros([batch, self.num_hidden[i], height, width]).to(\n",
    "                self.configs.device\n",
    "            )\n",
    "            h_t.append(zeros)\n",
    "            c_t.append(zeros)\n",
    "\n",
    "        memory = torch.zeros([batch, self.num_hidden[0], height, width]).to(\n",
    "            self.configs.device\n",
    "        )\n",
    "\n",
    "        for t in range(self.configs.total_length - 1):\n",
    "            # reverse schedule sampling\n",
    "            if self.configs.reverse_scheduled_sampling == 1:\n",
    "                if t == 0:\n",
    "                    net = frames[:, t]\n",
    "                else:\n",
    "                    net = (\n",
    "                        mask_true[:, t - 1] * frames[:, t]\n",
    "                        + (1 - mask_true[:, t - 1]) * x_gen\n",
    "                    )\n",
    "            else:\n",
    "                if t < self.configs.input_length:\n",
    "                    net = frames[:, t]\n",
    "                else:\n",
    "                    net = (\n",
    "                        mask_true[:, t - self.configs.input_length] * frames[:, t]\n",
    "                        + (1 - mask_true[:, t - self.configs.input_length]) * x_gen\n",
    "                    )\n",
    "\n",
    "            h_t[0], c_t[0], memory = self.cell_list[0](net, h_t[0], c_t[0], memory)\n",
    "\n",
    "            for i in range(1, self.num_layers):\n",
    "                h_t[i], c_t[i], memory = self.cell_list[i](\n",
    "                    h_t[i - 1], h_t[i], c_t[i], memory\n",
    "                )\n",
    "\n",
    "            x_gen = self.conv_last(h_t[self.num_layers - 1])\n",
    "            next_frames.append(x_gen)\n",
    "\n",
    "        # [length, batch, channel, height, width] -> [batch, length, height, width, channel]\n",
    "        next_frames = (\n",
    "            torch.stack(next_frames, dim=0).permute(1, 0, 3, 4, 2).contiguous()\n",
    "        )\n",
    "        loss = self.MSE_criterion(next_frames, frames_tensor[:, 1:])\n",
    "        return next_frames, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 3\n",
    "num_hidden = 6\n",
    "width = 32\n",
    "filter_size = 5\n",
    "stride = 1  # Does not seem to work when stride ~= 1\n",
    "layer_norm = False\n",
    "\n",
    "lstm = SpatioTemporalLSTMCell(\n",
    "    in_channel, num_hidden, width, filter_size, stride, layer_norm\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 6, 32, 32]) torch.Size([11, 6, 32, 32]) torch.Size([11, 6, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 11\n",
    "\n",
    "X = torch.rand(batch_size, in_channel, width, width)\n",
    "h = torch.rand(batch_size, num_hidden, width, width)\n",
    "c = torch.rand(batch_size, num_hidden, width, width)\n",
    "m = torch.rand(batch_size, num_hidden, width, width)\n",
    "\n",
    "h, c, m = lstm(X, h, c, m)\n",
    "\n",
    "print(h.size(), c.size(), m.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "num_hidden = [20, 30, 40]  # Hidden layer channel\n",
    "patch_size = 1\n",
    "stride = 1\n",
    "img_width = 32\n",
    "layer_norm = False\n",
    "filter_size = 5\n",
    "img_channel = 3\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(\n",
    "        self, patch_size, stride, img_width, img_channel, layer_norm, filter_size\n",
    "    ):\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.img_width = img_width\n",
    "        self.img_channel = img_channel\n",
    "        self.layer_norm = layer_norm\n",
    "        self.filter_size = filter_size\n",
    "\n",
    "\n",
    "configs = Configs(patch_size, stride, img_width, img_channel, layer_norm, filter_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(num_layers=num_layers, num_hidden=num_hidden, configs=configs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d201a29f7c4182ebe0d045b868be9ef5a41c2ba4cccd19f1728f184a837bb8e6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
