{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatioTemporalLSTMCell(nn.Module):\n",
    "    def __init__(self, in_channel, num_hidden, width, filter_size, stride, layer_norm):\n",
    "        super(SpatioTemporalLSTMCell, self).__init__()\n",
    "\n",
    "        self.num_hidden = num_hidden\n",
    "        self.padding = filter_size // 2\n",
    "        self._forget_bias = 1.0\n",
    "        if layer_norm:\n",
    "            self.conv_x = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channel,\n",
    "                    num_hidden * 7,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.LayerNorm([num_hidden * 7, width, width]),\n",
    "            )\n",
    "            self.conv_h = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden,\n",
    "                    num_hidden * 4,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.LayerNorm([num_hidden * 4, width, width]),\n",
    "            )\n",
    "            self.conv_m = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden,\n",
    "                    num_hidden * 3,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.LayerNorm([num_hidden * 3, width, width]),\n",
    "            )\n",
    "            self.conv_o = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden * 2,\n",
    "                    num_hidden,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.LayerNorm([num_hidden, width, width]),\n",
    "            )\n",
    "        else:\n",
    "            self.conv_x = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channel,\n",
    "                    num_hidden * 7,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "            self.conv_h = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden,\n",
    "                    num_hidden * 4,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "            self.conv_m = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden,\n",
    "                    num_hidden * 3,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "            self.conv_o = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    num_hidden * 2,\n",
    "                    num_hidden,\n",
    "                    kernel_size=filter_size,\n",
    "                    stride=stride,\n",
    "                    padding=self.padding,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            )\n",
    "        self.conv_last = nn.Conv2d(\n",
    "            num_hidden * 2, num_hidden, kernel_size=1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x_t, h_t, c_t, m_t):\n",
    "        x_concat = self.conv_x(x_t)\n",
    "        h_concat = self.conv_h(h_t)\n",
    "        m_concat = self.conv_m(m_t)\n",
    "        i_x, f_x, g_x, i_x_prime, f_x_prime, g_x_prime, o_x = torch.split(\n",
    "            x_concat, self.num_hidden, dim=1\n",
    "        )\n",
    "        i_h, f_h, g_h, o_h = torch.split(h_concat, self.num_hidden, dim=1)\n",
    "        i_m, f_m, g_m = torch.split(m_concat, self.num_hidden, dim=1)\n",
    "\n",
    "        i_t = torch.sigmoid(i_x + i_h)\n",
    "        f_t = torch.sigmoid(f_x + f_h + self._forget_bias)\n",
    "        g_t = torch.tanh(g_x + g_h)\n",
    "\n",
    "        c_new = f_t * c_t + i_t * g_t\n",
    "\n",
    "        i_t_prime = torch.sigmoid(i_x_prime + i_m)\n",
    "        f_t_prime = torch.sigmoid(f_x_prime + f_m + self._forget_bias)\n",
    "        g_t_prime = torch.tanh(g_x_prime + g_m)\n",
    "\n",
    "        m_new = f_t_prime * m_t + i_t_prime * g_t_prime\n",
    "\n",
    "        mem = torch.cat((c_new, m_new), 1)\n",
    "        o_t = torch.sigmoid(o_x + o_h + self.conv_o(mem))\n",
    "        h_new = o_t * torch.tanh(self.conv_last(mem))\n",
    "\n",
    "        return h_new, c_new, m_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, num_layers, num_hidden, configs):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.configs = configs\n",
    "        self.frame_channel = (\n",
    "            configs.patch_size * configs.patch_size * configs.img_channel\n",
    "        )\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        cell_list = []\n",
    "\n",
    "        width = configs.img_width // configs.patch_size\n",
    "        self.MSE_criterion = nn.MSELoss()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            in_channel = self.frame_channel if i == 0 else num_hidden[i - 1]\n",
    "            cell_list.append(\n",
    "                SpatioTemporalLSTMCell(\n",
    "                    in_channel,\n",
    "                    num_hidden[i],\n",
    "                    width,\n",
    "                    configs.filter_size,\n",
    "                    configs.stride,\n",
    "                    configs.layer_norm,\n",
    "                )\n",
    "            )\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "        self.conv_last = nn.Conv2d(\n",
    "            num_hidden[num_layers - 1],\n",
    "            self.frame_channel,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, frames_tensor, mask_true):\n",
    "        # [batch, length, height, width, channel] -> [batch, length, channel, height, width]\n",
    "        frames = frames_tensor.permute(0, 1, 4, 2, 3).contiguous()\n",
    "        mask_true = mask_true.permute(0, 1, 4, 2, 3).contiguous()\n",
    "\n",
    "        batch = frames.shape[0]\n",
    "        height = frames.shape[3]\n",
    "        width = frames.shape[4]\n",
    "\n",
    "        next_frames = []\n",
    "        h_t = []\n",
    "        c_t = []\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            zeros = torch.zeros([batch, self.num_hidden[i], height, width]).to(\n",
    "                self.configs.device\n",
    "            )\n",
    "            h_t.append(zeros)\n",
    "            c_t.append(zeros)\n",
    "\n",
    "        memory = torch.zeros([batch, self.num_hidden[0], height, width]).to(\n",
    "            self.configs.device\n",
    "        )\n",
    "\n",
    "        for t in range(self.configs.total_length - 1):\n",
    "            # reverse schedule sampling\n",
    "            if self.configs.reverse_scheduled_sampling == 1:\n",
    "                if t == 0:\n",
    "                    net = frames[:, t]\n",
    "                else:\n",
    "                    net = (\n",
    "                        mask_true[:, t - 1] * frames[:, t]\n",
    "                        + (1 - mask_true[:, t - 1]) * x_gen\n",
    "                    )\n",
    "            else:\n",
    "                if t < self.configs.input_length:\n",
    "                    net = frames[:, t]\n",
    "                else:\n",
    "                    net = (\n",
    "                        mask_true[:, t - self.configs.input_length] * frames[:, t]\n",
    "                        + (1 - mask_true[:, t - self.configs.input_length]) * x_gen\n",
    "                    )\n",
    "\n",
    "            h_t[0], c_t[0], memory = self.cell_list[0](net, h_t[0], c_t[0], memory)\n",
    "\n",
    "            for i in range(1, self.num_layers):\n",
    "                h_t[i], c_t[i], memory = self.cell_list[i](\n",
    "                    h_t[i - 1], h_t[i], c_t[i], memory\n",
    "                )\n",
    "\n",
    "            x_gen = self.conv_last(h_t[self.num_layers - 1])\n",
    "            next_frames.append(x_gen)\n",
    "\n",
    "        # [length, batch, channel, height, width] -> [batch, length, height, width, channel]\n",
    "        next_frames = (\n",
    "            torch.stack(next_frames, dim=0).permute(1, 0, 3, 4, 2).contiguous()\n",
    "        )\n",
    "        loss = self.MSE_criterion(next_frames, frames_tensor[:, 1:])\n",
    "        return next_frames, loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_channel = 3\n",
    "# num_hidden = 6\n",
    "# width = 32\n",
    "# filter_size = 5\n",
    "# stride = 1  # Does not seem to work when stride ~= 1\n",
    "# layer_norm = False\n",
    "\n",
    "# lstm = SpatioTemporalLSTMCell(\n",
    "#     in_channel, num_hidden, width, filter_size, stride, layer_norm\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 11\n",
    "\n",
    "# X = torch.rand(batch_size, in_channel, width, width)\n",
    "# h = torch.rand(batch_size, num_hidden, width, width)\n",
    "# c = torch.rand(batch_size, num_hidden, width, width)\n",
    "# m = torch.rand(batch_size, num_hidden, width, width)\n",
    "\n",
    "# h, c, m = lstm(X, h, c, m)\n",
    "\n",
    "# print(h.size(), c.size(), m.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "num_hidden = [\n",
    "    30,\n",
    "    30,\n",
    "    30,\n",
    "]  # Hidden layer channel. Note that this code does not support different number of hidden filters for each layer\n",
    "patch_size = 1\n",
    "stride = 1\n",
    "img_width = 32\n",
    "layer_norm = True\n",
    "filter_size = 5\n",
    "img_channel = 3\n",
    "# Not sure what is the different between input_length and sequence_length. But I will set it equal for now.\n",
    "input_length = 10  # Sequence length\n",
    "total_length = input_length\n",
    "\n",
    "\n",
    "class Configs:\n",
    "    def __init__(\n",
    "        self,\n",
    "        patch_size,\n",
    "        stride,\n",
    "        img_width,\n",
    "        img_channel,\n",
    "        layer_norm,\n",
    "        filter_size,\n",
    "        input_length,\n",
    "        total_length,\n",
    "    ):\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.img_width = img_width\n",
    "        self.img_channel = img_channel\n",
    "        self.layer_norm = layer_norm\n",
    "        self.filter_size = filter_size\n",
    "        self.input_length = input_length\n",
    "        self.total_length = total_length\n",
    "\n",
    "\n",
    "configs = Configs(\n",
    "    patch_size,\n",
    "    stride,\n",
    "    img_width,\n",
    "    img_channel,\n",
    "    layer_norm,\n",
    "    filter_size,\n",
    "    input_length,\n",
    "    total_length,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(num_layers=num_layers, num_hidden=num_hidden, configs=configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 10, 32, 32, 3])\n",
      "torch.Size([11, 10, 3, 32, 32])\n",
      "11 32 32\n",
      "h torch.Size([11, 30, 32, 32])\n",
      "h torch.Size([11, 30, 32, 32])\n",
      "h torch.Size([11, 30, 32, 32])\n",
      "m torch.Size([11, 30, 32, 32])\n",
      "------t=0--------\n",
      "net torch.Size([11, 3, 32, 32])\n",
      "i=0\n",
      "torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32])\n",
      "i=1\n",
      "torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32])\n",
      "i=2\n",
      "torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32])\n",
      "x_gen torch.Size([11, 3, 32, 32])\n",
      "------t=1--------\n",
      "net torch.Size([11, 3, 32, 32])\n",
      "i=0\n",
      "torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32])\n",
      "i=1\n",
      "torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32])\n",
      "i=2\n",
      "torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32]) torch.Size([11, 30, 32, 32])\n",
      "x_gen torch.Size([11, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 11\n",
    "seq_length = 10\n",
    "in_channel = 3\n",
    "\n",
    "frames_tensor = torch.rand(batch_size, seq_length, img_width, img_width, in_channel)\n",
    "print(frames_tensor.size())\n",
    "frames = frames_tensor.permute(0, 1, 4, 2, 3).contiguous()\n",
    "print(frames.size())\n",
    "\n",
    "batch = frames.shape[0]\n",
    "height = frames.shape[3]\n",
    "width = frames.shape[4]\n",
    "print(batch, height, width)\n",
    "\n",
    "next_frames = []\n",
    "h_t = []\n",
    "c_t = []\n",
    "\n",
    "for i in range(num_layers):\n",
    "    zeros = torch.zeros([batch, num_hidden[i], height, width])\n",
    "    h_t.append(zeros)\n",
    "    c_t.append(zeros)\n",
    "\n",
    "for h in h_t:\n",
    "    print(\"h\", h.size())\n",
    "\n",
    "memory = torch.zeros([batch, num_hidden[0], height, width])\n",
    "\n",
    "print(\"m\", memory.size())\n",
    "\n",
    "for t in range(2):\n",
    "    print(f\"------t={t}--------\")\n",
    "    net = frames[:, t]\n",
    "    print(\"net\", net.size())\n",
    "\n",
    "    print(f\"i={0}\")\n",
    "    h_t[0], c_t[0], memory = model.cell_list[0](net, h_t[0], c_t[0], memory)\n",
    "    print(h_t[0].size(), c_t[0].size(), memory.size())\n",
    "    for i in range(1, num_layers):\n",
    "        print(f\"i={i}\")\n",
    "        h_t[i], c_t[i], memory = model.cell_list[i](h_t[i - 1], h_t[i], c_t[i], memory)\n",
    "        print(h_t[0].size(), c_t[0].size(), memory.size())\n",
    "\n",
    "    x_gen = model.conv_last(h_t[num_layers - 1])\n",
    "    next_frames.append(x_gen)\n",
    "    print(\"x_gen\", x_gen.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatioTemporalLSTMCell(\n",
       "  (conv_x): Sequential(\n",
       "    (0): Conv2d(3, 210, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (1): LayerNorm((210, 32, 32), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (conv_h): Sequential(\n",
       "    (0): Conv2d(30, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (1): LayerNorm((120, 32, 32), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (conv_m): Sequential(\n",
       "    (0): Conv2d(30, 90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (1): LayerNorm((90, 32, 32), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (conv_o): Sequential(\n",
       "    (0): Conv2d(60, 30, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "    (1): LayerNorm((30, 32, 32), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(60, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cell_list[0]\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1b9c7f2f57af8f07e064f2c72ed76cd3499c7b2fb82bb3d901b6e74555bba53"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
