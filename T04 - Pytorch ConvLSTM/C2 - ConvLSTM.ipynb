{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Original ConvLSTM cell as proposed by Shi et al.\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, padding, activation, frame_size\n",
    "    ):\n",
    "\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        if activation == \"tanh\":\n",
    "            self.activation = torch.tanh\n",
    "        elif activation == \"relu\":\n",
    "            self.activation = torch.relu\n",
    "\n",
    "        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels + out_channels,\n",
    "            out_channels=4 * out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "        # Initialize weights for Hadamard Products\n",
    "        self.W_ci = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
    "        self.W_co = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
    "        self.W_cf = nn.Parameter(torch.Tensor(out_channels, *frame_size))\n",
    "\n",
    "    def forward(self, X, H_prev, C_prev):\n",
    "\n",
    "        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch\n",
    "        conv_output = self.conv(torch.cat([X, H_prev], dim=1))\n",
    "\n",
    "        # Idea adapted from https://github.com/ndrplz/ConvLSTM_pytorch\n",
    "        i_conv, f_conv, C_conv, o_conv = torch.chunk(conv_output, chunks=4, dim=1)\n",
    "\n",
    "        input_gate = torch.sigmoid(i_conv + self.W_ci * C_prev)\n",
    "        forget_gate = torch.sigmoid(f_conv + self.W_cf * C_prev)\n",
    "\n",
    "        # Current Cell output\n",
    "        C = forget_gate * C_prev + input_gate * self.activation(C_conv)\n",
    "\n",
    "        output_gate = torch.sigmoid(o_conv + self.W_co * C)\n",
    "\n",
    "        # Current Hidden State\n",
    "        H = output_gate * self.activation(C)\n",
    "\n",
    "        return H, C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, padding, activation, frame_size\n",
    "    ):\n",
    "\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        # We will unroll this over time steps\n",
    "        self.convLSTMcell = ConvLSTMCell(\n",
    "            in_channels, out_channels, kernel_size, padding, activation, frame_size\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        # X is a frame sequence (batch_size, num_channels, seq_len, height, width)\n",
    "\n",
    "        # Get the dimensions\n",
    "        batch_size, _, seq_len, height, width = X.size()\n",
    "\n",
    "        # Initialize output\n",
    "        output = torch.zeros(\n",
    "            batch_size, self.out_channels, seq_len, height, width, device=device\n",
    "        )\n",
    "\n",
    "        # Initialize Hidden State\n",
    "        H = torch.rand(batch_size, self.out_channels, height, width, device=device)\n",
    "\n",
    "        # Initialize Cell Input\n",
    "        C = torch.rand(batch_size, self.out_channels, height, width, device=device)\n",
    "\n",
    "        # Unroll over time steps\n",
    "        for time_step in range(seq_len):\n",
    "\n",
    "            H, C = self.convLSTMcell(X[:, :, time_step], H, C)\n",
    "\n",
    "            output[:, :, time_step] = H\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_channels,\n",
    "        num_kernels,\n",
    "        kernel_size,\n",
    "        padding,\n",
    "        activation,\n",
    "        frame_size,\n",
    "        num_layers,\n",
    "    ):\n",
    "\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.sequential = nn.Sequential()\n",
    "\n",
    "        # Add First layer (Different in_channels than the rest)\n",
    "        self.sequential.add_module(\n",
    "            \"convlstm1\",\n",
    "            ConvLSTM(\n",
    "                in_channels=num_channels,\n",
    "                out_channels=num_kernels,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=padding,\n",
    "                activation=activation,\n",
    "                frame_size=frame_size,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.sequential.add_module(\n",
    "            \"batchnorm1\", nn.BatchNorm3d(num_features=num_kernels)\n",
    "        )\n",
    "\n",
    "        # Add rest of the layers\n",
    "        for l in range(2, num_layers + 1):\n",
    "\n",
    "            self.sequential.add_module(\n",
    "                f\"convlstm{l}\",\n",
    "                ConvLSTM(\n",
    "                    in_channels=num_kernels,\n",
    "                    out_channels=num_kernels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=padding,\n",
    "                    activation=activation,\n",
    "                    frame_size=frame_size,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            self.sequential.add_module(\n",
    "                f\"batchnorm{l}\", nn.BatchNorm3d(num_features=num_kernels)\n",
    "            )\n",
    "\n",
    "        # Add Convolutional Layer to predict output frame\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=num_kernels,\n",
    "            out_channels=num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        # Forward propagation through all the layers\n",
    "        output = self.sequential(X)\n",
    "\n",
    "        # Return only the last output frame\n",
    "        output = self.conv(output[:, :, -1])\n",
    "\n",
    "        return nn.Sigmoid()(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `ConvLSTMCell` and `ConvLSTM` classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 1\n",
    "out_channels = 10\n",
    "kernel_size = 3\n",
    "padding = \"same\"\n",
    "activation = \"relu\"\n",
    "frame_size = (5, 5)\n",
    "batch_size = 3\n",
    "seq_length = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = ConvLSTMCell(\n",
    "    in_channels, out_channels, kernel_size, padding, activation, frame_size\n",
    ")\n",
    "torch.manual_seed(0)\n",
    "X = torch.rand(batch_size, in_channels, seq_length, *frame_size)\n",
    "H = torch.rand(batch_size, out_channels, *frame_size)\n",
    "C = torch.rand(batch_size, out_channels, *frame_size)\n",
    "O1 = torch.zeros(batch_size, out_channels, seq_length, *frame_size)\n",
    "for timestep in range(seq_length):\n",
    "    H, C = lstm1(X[:, :, timestep], H, C)\n",
    "    O1[:, :, timestep] = H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2 = ConvLSTM(\n",
    "    in_channels, out_channels, kernel_size, padding, activation, frame_size\n",
    ")\n",
    "torch.manual_seed(0)\n",
    "X = torch.rand(batch_size, in_channels, seq_length, *frame_size)\n",
    "O2 = lstm2(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1731, 0.1340, 0.5377, 0.5744, 0.2173], grad_fn=<SelectBackward0>)\n",
      "tensor([0.9033, 0.0483, 0.6721, 0.3117, 0.1132], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# This should give the same answer.\n",
    "print(O1[0, 0, 0, 0])\n",
    "print(O2[0, 0, 0, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `Seq2Seq` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 10, 5, 5])\n",
      "torch.Size([3, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "num_channels = in_channels\n",
    "num_kernels = out_channels\n",
    "num_layers = 3\n",
    "\n",
    "lstm3 = Seq2Seq(\n",
    "    num_channels, num_kernels, kernel_size, padding, activation, frame_size, num_layers\n",
    ")\n",
    "\n",
    "X = torch.rand(batch_size, num_channels, seq_length, *frame_size)\n",
    "O3 = lstm3(X)\n",
    "\n",
    "print(X.size())\n",
    "print(O3.size())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1b9c7f2f57af8f07e064f2c72ed76cd3499c7b2fb82bb3d901b6e74555bba53"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
