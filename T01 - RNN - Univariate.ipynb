{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network - Univariate\n",
    "- Simple RNN\n",
    "- LSTM\n",
    "- GRU\n",
    "- https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to use LSTM and GRU, you need to downgrade numpy\n",
    "- `conda create --name tf tensorflow=2.4`\n",
    "- `conda activate tf`\n",
    "- `conda install numpy=1.19`\n",
    "- `conda install jupyterlab matplotlib pandas`\n",
    "- https://stackoverflow.com/questions/66207609/notimplementederror-cannot-convert-a-symbolic-tensor-lstm-2-strided-slice0-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1-Time1</th>\n",
       "      <th>X1-Time2</th>\n",
       "      <th>X1-Time3</th>\n",
       "      <th>X1-Time4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1-Time1  X1-Time2  X1-Time3  X1-Time4   y\n",
       "sample                                            \n",
       "0             10        20        30        40  50\n",
       "1             20        30        40        50  60\n",
       "2             30        40        50        60  70\n",
       "3             40        50        60        70  80\n",
       "4             50        60        70        80  90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split into samples\n",
    "X_, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# visualize input\n",
    "temp = pd.DataFrame(data=X_, columns=['X1-Time1','X1-Time2','X1-Time3','X1-Time4'])\n",
    "temp['y'] = y\n",
    "temp.index.name='sample'\n",
    "display(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_steps = 2\n",
    "X = X_.reshape((X_.shape[0], n_seq, 1, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, SimpleRNN, GRU, Conv1D, MaxPooling1D, Flatten, ConvLSTM2D\n",
    "\n",
    "def createModel(type):\n",
    "    inputLayer = Input(shape=(n_seq, 1, n_steps, n_features))\n",
    "\n",
    "    if (type == 'ConvLSTM'):\n",
    "        layer = ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu')(inputLayer)\n",
    "        layer = Flatten()(layer)\n",
    "    \n",
    "    outputLayer = Dense(1)(layer)\n",
    "    model = Model(inputs=inputLayer, outputs=outputLayer, name=type)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ConvLSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2, 1, 2, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 1, 1, 64)          33536     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 33,601\n",
      "Trainable params: 33,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model building\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(1)\n",
    "# For somereason if I don't include this, I cannot execute this cell twice for LSTM and GRU\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "\n",
    "ConvLSTM = createModel('ConvLSTM')\n",
    "\n",
    "ConvLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def runModel(model, X, y, **kwargs):\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    if 'learning_rate' in kwargs:\n",
    "        learning_rate = kwargs['learning_rate']\n",
    "\n",
    "    patience = 10\n",
    "    if 'patience' in kwargs:\n",
    "        patience = kwargs['patience']\n",
    "\n",
    "    epochs=200\n",
    "    if 'epochs' in kwargs:\n",
    "        epochs = kwargs['epochs']\n",
    "\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    earlyStoppingCallback = EarlyStopping(monitor='loss', patience=patience, min_delta=0)\n",
    "\n",
    "    history = model.fit(X, y, epochs=epochs, verbose=1, callbacks=[earlyStoppingCallback ])\n",
    "\n",
    "    hist = history.history\n",
    "    x_arr = np.arange(len(hist['loss'])) + 1\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(x_arr, hist['loss'], '-o', label='Train loss')\n",
    "    ax.set_xlabel('Epoch', size=15)\n",
    "    ax.set_ylabel('Loss', size=15)\n",
    "    ax.legend(fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 08:52:05.280520: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-29 08:52:05.304280: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1999965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 5134.6670\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5053.9941\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4972.5039\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4889.2861\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4804.0039\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4717.9648\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4629.6606\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4540.8291\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4450.1611\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4356.3149\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4260.6514\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4164.7837\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4067.2786\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3968.2227\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3867.7375\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3764.7231\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3659.3113\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3550.1394\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3440.1753\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3328.5125\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3219.9512\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3110.2039\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2998.7612\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2886.4917\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2776.2173\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 2665.8062\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2555.3376\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2441.4751\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2326.4036\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2207.6641\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2084.4695\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1960.9744\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1836.6459\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1713.5303\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1591.6909\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1471.9385\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1353.8175\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1235.8928\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1119.4302\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1004.8771\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 893.3530\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 785.9854\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 683.5805\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 586.6615\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 496.6820\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 416.8635\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 347.2684\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 289.9140\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 240.8192\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 201.5489\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 170.8031\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 148.0406\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 133.0583\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 125.1468\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 123.2410\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 126.3445\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 131.9462\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 138.1491\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 143.6373\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 147.7871\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 150.5195\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 151.4259\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 150.5514\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 148.2257\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 144.6973\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 140.3472\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 135.5280\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 130.5668\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 125.9669\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 122.1655\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 118.7817\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 115.6424\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 112.8639\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 110.3833\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 108.2957\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 106.5600\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 105.1321\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 103.9371\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 102.8480\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 101.9744\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 101.3352\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 100.9943\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 100.5569\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 100.0777\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 99.5140\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 98.8644\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 98.1573\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 97.4562\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 96.7822\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 95.8844\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 95.1299\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 94.2963\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 93.3478\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 92.2899\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 91.1745\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 90.2082\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 89.1228\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 88.3878\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 87.4523\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 86.2244\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 85.5330\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 84.7447\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 83.8475\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 82.8583\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 81.8075\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 80.7143\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 79.6124\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 78.9341\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 77.5535\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 76.5833\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 75.6184\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 74.8103\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 73.8764\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 72.6622\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 71.2550\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 70.0712\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 68.9009\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 67.9852\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 66.5841\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 65.3952\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 64.4430\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 63.3256\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 62.0560\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 60.7491\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 59.6874\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 58.3923\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 57.3306\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 56.4185\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 55.3778\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 54.1757\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 52.8422\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 51.5623\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 50.4961\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 49.4289\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 48.3075\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 47.1066\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 45.8445\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 44.5455\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 43.3665\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 42.2633\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 41.0826\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 39.8313\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 38.5498\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 37.2898\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 36.1295\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 34.8970\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 33.7489\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 32.6591\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 31.6368\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 30.5865\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 29.5628\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 28.5143\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27.4400\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 26.3499\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 25.2785\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 24.2141\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 23.1933\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 22.2057\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 21.2184\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 20.2707\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 19.3467\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18.4406\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 17.5678\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 16.7294\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 15.9250\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 15.2141\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 14.5317\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 13.8978\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 13.3068\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 12.7513\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 12.2234\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 11.7151\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.2208\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 10.7325\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 10.2427\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 9.7655\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.3124\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.8700\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 8.4499\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.0421\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6356\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.3180\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.0894\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.8496\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 6.5970\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.3787\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.1889\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.9781\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.7873\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.6292\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.4674\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.2985\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.1531\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.0334\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9119\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.7969\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.6997\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5988\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4897\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3894\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2930\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.1868\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.0808\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.9818\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8797\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7746\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.6760\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.5807\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.4832\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.3911\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.3042\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.2156\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.1302\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.0477\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.9634\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.8796\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.7982\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.7155\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.6327\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.5556\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.4788\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.4023\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3288\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.2665\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.2048\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.1454\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.0882\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0306\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9744\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.9196\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8650\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8122\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.7573\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7007\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.6459\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5946\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5441\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4954\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.4475\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.4021\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.3576\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3126\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2678\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.2228\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.1775\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1381\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0938\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0532\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0143\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.9739\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9345\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8953\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.8536\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8142\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7768\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7384\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7021\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6676\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6311\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5968\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5646\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.5329\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5052\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4753\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4476\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4199\n",
      "Epoch 267/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3950\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3699\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3461\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3221\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3003\n",
      "Epoch 272/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2783\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2569\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2378\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2181\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1995\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1822\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1655\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1492\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1353\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1217\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1110\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0984\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0864\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0767\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0673\n",
      "Epoch 287/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0589\n",
      "Epoch 288/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0511\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0438\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0375\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0315\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0264\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0218\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0177\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0141\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0110\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0087\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0065\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0047\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0034\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0024\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0015\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.8995e-04\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.8672e-04\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.8673e-04\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.7475e-04\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6677e-04\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0019\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0051\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0070\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0031\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.1906e-04\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0048\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0053\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.6397e-04\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0034\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7231e-04\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0024\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0018\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.7006e-04\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0022\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.1068e-04\n",
      "Epoch 324/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.9854e-04\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0015\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.4256e-04\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.9188e-04\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 8.3496e-04\n",
      "Epoch 329/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.3088e-05\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 8.5469e-04\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.4561e-04\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.2109e-04\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.8597e-04\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.1063e-05\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.4742e-04\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.5470e-04\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.2498e-05\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.7827e-04\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 2.1525e-04\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 7.0994e-05\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2600e-04\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 8.3465e-05\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0523e-04\n",
      "Epoch 344/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1138e-04\n",
      "Epoch 345/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.8549e-05\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3214e-04\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2193e-04\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.1843e-06\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1865e-04\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6660e-05\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.3278e-05\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.6486e-05\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7582e-05\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.3215e-05\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.9272e-05\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.3841e-06\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.9281e-05\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.2071e-05\n",
      "Epoch 359/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9872e-06\n",
      "Epoch 360/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.9334e-05\n",
      "Epoch 361/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.5809e-05\n",
      "Epoch 362/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.8223e-06\n",
      "Epoch 363/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.1287e-05\n",
      "Epoch 364/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3472e-05\n",
      "Epoch 365/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.0590e-06\n",
      "Epoch 366/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.4045e-05\n",
      "Epoch 367/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.6196e-06\n",
      "Epoch 368/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.2194e-06\n",
      "Epoch 369/2000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.6963e-05\n",
      "Epoch 370/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 2.6215e-06\n",
      "Epoch 371/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0883e-06\n",
      "Epoch 372/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.1262e-05\n",
      "Epoch 373/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 8.7805e-07\n",
      "Epoch 374/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.0062e-06\n",
      "Epoch 375/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.3284e-06\n",
      "Epoch 376/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.8413e-07\n",
      "Epoch 377/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.9836e-06\n",
      "Epoch 378/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.9302e-06\n",
      "Epoch 379/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.6083e-07\n",
      "Epoch 380/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2316e-06\n",
      "Epoch 381/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.0747e-06\n",
      "Epoch 382/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.4090e-07\n",
      "Epoch 383/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.3069e-06\n",
      "Epoch 384/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.0216e-06\n",
      "Epoch 385/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.3042e-07\n",
      "Epoch 386/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3334e-06\n",
      "Epoch 387/2000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 2.1121e-06\n",
      "Epoch 388/2000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 2.0096e-07\n",
      "Epoch 389/2000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.7354e-06\n",
      "Epoch 390/2000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.5208e-06\n",
      "Epoch 391/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.6848e-08\n",
      "Epoch 392/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.1991e-06\n",
      "Epoch 393/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2014e-06\n",
      "Epoch 394/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1354e-08\n",
      "Epoch 395/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.8751e-07\n",
      "Epoch 396/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.0418e-07\n",
      "Epoch 397/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.1299e-08\n",
      "Epoch 398/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.5936e-07\n",
      "Epoch 399/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 7.0806e-07\n",
      "Epoch 400/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.4567e-08\n",
      "Epoch 401/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7377e-07\n",
      "Epoch 402/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.0143e-07\n",
      "Epoch 403/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0569e-07\n",
      "Epoch 404/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.1032e-07\n",
      "Epoch 405/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.5621e-07\n",
      "Epoch 406/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.2296e-07\n",
      "Epoch 407/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1292e-07\n",
      "Epoch 408/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2272e-07\n",
      "Epoch 409/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0631e-07\n",
      "Epoch 410/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.4226e-08\n",
      "Epoch 411/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.3683e-07\n",
      "Epoch 412/2000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1991e-07\n",
      "Epoch 413/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.1846e-09\n",
      "Epoch 414/2000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.4206e-07\n",
      "Epoch 415/2000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.1884e-07\n",
      "Epoch 416/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.3254e-09\n",
      "Epoch 417/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.8260e-08\n",
      "Epoch 418/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.1303e-07\n",
      "Epoch 419/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5623e-08\n",
      "Epoch 420/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3027e-08\n",
      "Epoch 421/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.7000e-08\n",
      "Epoch 422/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3007e-08\n",
      "Epoch 423/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5413e-08\n",
      "Epoch 424/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.3973e-08\n",
      "Epoch 425/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1959e-08\n",
      "Epoch 426/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.6520e-09\n",
      "Epoch 427/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.2413e-08\n",
      "Epoch 428/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.4881e-08\n",
      "Epoch 429/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.6933e-09\n",
      "Epoch 430/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2189e-08\n",
      "Epoch 431/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.0748e-08\n",
      "Epoch 432/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.3347e-09\n",
      "Epoch 433/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.7474e-09\n",
      "Epoch 434/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2392e-08\n",
      "Epoch 435/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 9.0979e-09\n",
      "Epoch 436/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.8103e-10\n",
      "Epoch 437/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.2541e-08\n",
      "Epoch 438/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1365e-08\n",
      "Epoch 439/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0041e-09\n",
      "Epoch 440/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.3010e-09\n",
      "Epoch 441/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.2078e-08\n",
      "Epoch 442/2000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.7253e-09\n",
      "Epoch 443/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.5524e-09\n",
      "Epoch 444/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0213e-08\n",
      "Epoch 445/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.1525e-09\n",
      "Epoch 446/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.6648e-10\n",
      "Epoch 447/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.9180e-09\n",
      "Epoch 448/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.8260e-09\n",
      "Epoch 449/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1438e-09\n",
      "Epoch 450/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8073e-09\n",
      "Epoch 451/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.4657e-09\n",
      "Epoch 452/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.6252e-09\n",
      "Epoch 453/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.8917e-10\n",
      "Epoch 454/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3481e-09\n",
      "Epoch 455/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.6258e-09\n",
      "Epoch 456/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 8.9058e-10\n",
      "Epoch 457/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7142e-09\n",
      "Epoch 458/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.5018e-09\n",
      "Epoch 459/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.2171e-09\n",
      "Epoch 460/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3388e-10\n",
      "Epoch 461/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.9034e-09\n",
      "Epoch 462/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3906e-09\n",
      "Epoch 463/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.2282e-09\n",
      "Epoch 464/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.6589e-10\n",
      "Epoch 465/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6676e-09\n",
      "Epoch 466/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.1100e-09\n",
      "Epoch 467/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.2282e-10\n",
      "Epoch 468/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.7311e-11\n",
      "Epoch 469/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 5.2969e-10\n",
      "Epoch 470/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.0268e-10\n",
      "Epoch 471/2000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0768e-10\n",
      "Epoch 472/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.4925e-11\n",
      "Epoch 473/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.4401e-11\n",
      "Epoch 474/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.9104e-12\n",
      "Epoch 475/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.4261e-10\n",
      "Epoch 476/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.4133e-10\n",
      "Epoch 477/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.6857e-10\n",
      "Epoch 478/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8.4401e-11\n",
      "Epoch 479/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8.4401e-11\n",
      "Epoch 480/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.3178e-10\n",
      "Epoch 481/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3970e-10\n",
      "Epoch 482/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 9.6043e-11\n",
      "Epoch 483/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.1595e-10\n",
      "Epoch 484/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.4878e-10\n",
      "Epoch 485/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.0268e-10\n",
      "Epoch 486/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.1118e-11\n",
      "Epoch 487/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.6939e-10\n",
      "Epoch 488/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.1595e-10\n",
      "Epoch 489/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.9477e-11\n",
      "Epoch 490/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2014e-10\n",
      "Epoch 491/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.1118e-10\n",
      "Epoch 492/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.6043e-11\n",
      "Epoch 493/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.7358e-10\n",
      "Epoch 494/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.6438e-10\n",
      "Epoch 495/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.0163e-10\n",
      "Epoch 496/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4552e-11\n",
      "Epoch 497/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 2.7358e-10\n",
      "Epoch 498/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.1327e-10\n",
      "Epoch 499/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.2014e-10\n",
      "Epoch 500/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 9.8953e-11\n",
      "Epoch 501/2000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.7462e-11\n",
      "Epoch 502/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 2.3865e-10\n",
      "Epoch 503/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.9954e-10\n",
      "Epoch 504/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6834e-10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runModel(ConvLSTM, X, y, learning_rate=0.001, epochs=2000, patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictValue(model, X_):\n",
    "    X = X_.reshape((1, n_seq, 1, n_steps, n_features))\n",
    "    yhat_ = model.predict(X, verbose=0)\n",
    "    yhat = yhat_.flatten()[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM: 101.327\n"
     ]
    }
   ],
   "source": [
    "X_ = np.array([60, 70, 80, 90])\n",
    "print(f\"ConvLSTM: {predictValue(ConvLSTM, X_):5.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "183983f8581d242f392f04aa55828dc2781ebbbbdf8bf6ac72073cf044539615"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
