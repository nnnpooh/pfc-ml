{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network - Univariate\n",
    "- Simple RNN\n",
    "- LSTM\n",
    "- GRU\n",
    "- https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to use LSTM and GRU, you need to downgrade numpy\n",
    "- `conda create --name tf tensorflow=2.4`\n",
    "- `conda activate tf`\n",
    "- `conda install numpy=1.19`\n",
    "- `conda install jupyterlab matplotlib pandas`\n",
    "- https://stackoverflow.com/questions/66207609/notimplementederror-cannot-convert-a-symbolic-tensor-lstm-2-strided-slice0-t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 19:01:32.405611: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of time steps\n",
    "n_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1-Time1</th>\n",
       "      <th>X1-Time2</th>\n",
       "      <th>X1-Time3</th>\n",
       "      <th>X1-Time4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1-Time1  X1-Time2  X1-Time3  X1-Time4   y\n",
       "sample                                            \n",
       "0             10        20        30        40  50\n",
       "1             20        30        40        50  60\n",
       "2             30        40        50        60  70\n",
       "3             40        50        60        70  80\n",
       "4             50        60        70        80  90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split into samples\n",
    "X_, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# visualize input\n",
    "temp = pd.DataFrame(data=X_, columns=['X1-Time1','X1-Time2','X1-Time3','X1-Time4'])\n",
    "temp['y'] = y\n",
    "temp.index.name='sample'\n",
    "display(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n",
    "n_features = 1\n",
    "n_seq = 2\n",
    "n_steps = 2\n",
    "X = X_.reshape((X_.shape[0], n_seq, 1, n_steps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, SimpleRNN, GRU, Conv1D, MaxPooling1D, Flatten, ConvLSTM2D\n",
    "\n",
    "def createModel(type):\n",
    "    inputLayer = Input(shape=(n_seq, 1, n_steps, n_features))\n",
    "\n",
    "    if (type == 'ConvLSTM'):\n",
    "        layer = ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu')(inputLayer)\n",
    "        layer = Flatten()(layer)\n",
    "    \n",
    "    outputLayer = Dense(1)(layer)\n",
    "    model = Model(inputs=inputLayer, outputs=outputLayer, name=type)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ConvLSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2, 1, 2, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 1, 1, 64)          33536     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 33,601\n",
      "Trainable params: 33,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 19:01:32.659224: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-29 19:01:32.662217: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Model building\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(1)\n",
    "# For somereason if I don't include this, I cannot execute this cell twice for LSTM and GRU\n",
    "from tensorflow.keras.layers import LSTM, GRU\n",
    "\n",
    "ConvLSTM = createModel('ConvLSTM')\n",
    "\n",
    "ConvLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def runModel(model, X, y, **kwargs):\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    if 'learning_rate' in kwargs:\n",
    "        learning_rate = kwargs['learning_rate']\n",
    "\n",
    "    patience = 10\n",
    "    if 'patience' in kwargs:\n",
    "        patience = kwargs['patience']\n",
    "\n",
    "    epochs=200\n",
    "    if 'epochs' in kwargs:\n",
    "        epochs = kwargs['epochs']\n",
    "\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "    earlyStoppingCallback = EarlyStopping(monitor='loss', patience=patience, min_delta=0)\n",
    "\n",
    "    history = model.fit(X, y, epochs=epochs, verbose=1, callbacks=[earlyStoppingCallback ])\n",
    "\n",
    "    hist = history.history\n",
    "    x_arr = np.arange(len(hist['loss'])) + 1\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(x_arr, hist['loss'], '-o', label='Train loss')\n",
    "    ax.set_xlabel('Epoch', size=15)\n",
    "    ax.set_ylabel('Loss', size=15)\n",
    "    ax.legend(fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 19:01:32.907251: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-29 19:01:32.924158: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3593185000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 5134.6670\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5053.9941\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4972.5039\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 4889.2861\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 4804.0039\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4717.9648\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4629.6606\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 4540.8291\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 4450.1611\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4356.3149\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4260.6514\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4164.7837\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 4067.2786\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3968.2227\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3867.7375\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3764.7231\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3659.3113\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3550.1394\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3440.1753\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3328.5125\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3219.9512\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3110.2039\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2998.7612\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2886.4917\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2776.2173\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2665.8059\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2555.3376\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2441.4751\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2326.4036\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2207.6641\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2084.4695\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1960.9746\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1836.6459\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1713.5303\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1591.6908\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1471.9385\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1353.8175\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1235.8927\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1119.4302\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1004.8771\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 893.3531\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 785.9854\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 683.5804\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 586.6614\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 496.6820\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 416.8635\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 347.2684\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 289.9140\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 240.8192\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 201.5489\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 170.8031\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 148.0406\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 133.0583\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 125.1468\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 123.2410\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 126.3445\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 131.9462\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 138.1491\n",
      "Epoch 59/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 143.6372\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 147.7871\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 150.5193\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 151.4259\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 150.5513\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 148.2257\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 144.6975\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 140.3471\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 135.5279\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 130.5668\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 125.9669\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 122.1654\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 118.7817\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 115.6424\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 112.8639\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 110.3833\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 108.2958\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 106.5600\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 105.1321\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 103.9371\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 102.8481\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 101.9745\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 101.3352\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 100.9943\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 100.5569\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 100.0777\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 99.5140\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 98.8644\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 98.1572\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 97.4562\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 96.7822\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 95.8844\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 95.1299\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 94.2963\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 93.3479\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 92.2900\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 91.1745\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 90.2082\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 89.1228\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 88.3878\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 87.4523\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 86.2244\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 85.5330\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 84.7448\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 83.8475\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 82.8583\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 81.8075\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 80.7143\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 79.6125\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 78.9341\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 77.5535\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 76.5833\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 75.6184\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 74.8103\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 73.8764\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 72.6622\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 71.2550\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 70.0713\n",
      "Epoch 117/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 68.9009\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 67.9852\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 66.5841\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 65.3952\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 64.4430\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 63.3256\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 62.0560\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 60.7491\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 59.6874\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 58.3923\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 57.3306\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 56.4186\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 55.3778\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 54.1757\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 52.8423\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 51.5623\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 50.4961\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 49.4289\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 48.3075\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 47.1066\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 45.8446\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 44.5455\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 43.3665\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 42.2633\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 41.0826\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 39.8313\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 38.5498\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 37.2898\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 36.1295\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 34.8970\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 33.7489\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 32.6591\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 31.6368\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 30.5865\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 29.5628\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 28.5143\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 27.4400\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 26.3499\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 25.2785\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 24.2141\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23.1933\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 22.2057\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 21.2184\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 20.2707\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19.3467\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 18.4406\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 17.5678\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16.7294\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 15.9250\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 15.2141\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 14.5317\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 13.8978\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.3068\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 12.7513\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12.2234\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.7151\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.2207\n",
      "Epoch 174/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 10.7325\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 10.2427\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7655\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 9.3124\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.8700\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.4499\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.0421\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.6356\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.3180\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 7.0894\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 6.8496\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 6.5970\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 6.3787\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.1889\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 5.9781\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5.7873\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 5.6292\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 5.4674\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.2985\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1531\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.0334\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 4.9119\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 4.7969\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.6997\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5988\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4897\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 4.3894\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2930\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.1868\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 4.0808\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.9818\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.8797\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7746\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.6760\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.5807\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.4832\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.3911\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.3042\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.2156\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.1301\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.0477\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9634\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.8796\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.7982\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.7155\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.6327\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.5556\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.4788\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4023\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3288\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2665\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2048\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.1454\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0882\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0306\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9744\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9196\n",
      "Epoch 231/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.8650\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8122\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7573\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7007\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.6459\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5945\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5441\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4954\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4476\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4021\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3576\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3126\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2678\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.2228\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1775\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1381\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0938\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.0532\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.0143\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9739\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9345\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8953\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8536\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8142\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7768\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7384\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7021\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6676\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6311\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5968\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5646\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5328\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5052\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4753\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4476\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4199\n",
      "Epoch 267/2000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3950\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3699\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3461\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3221\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3003\n",
      "Epoch 272/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2783\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2569\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2378\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2181\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1995\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1822\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1655\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1492\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1353\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1217\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1110\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0984\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0864\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0767\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0673\n",
      "Epoch 287/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0589\n",
      "Epoch 288/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0511\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0438\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0375\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0315\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0264\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0218\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0177\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0141\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0110\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0087\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0065\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0047\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0034\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0024\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0015\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.8972e-04\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.8624e-04\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.8640e-04\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.7389e-04\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.6458e-04\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0019\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0051\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0070\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0031\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.1591e-04\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0048\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0053\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.6488e-04\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0023\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0034\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.7226e-04\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0024\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7544e-04\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0022\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0506e-04\n",
      "Epoch 324/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0891e-04\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0015\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3954e-04\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.0361e-04\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.2903e-04\n",
      "Epoch 329/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.5844e-05\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.6220e-04\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3861e-04\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.2902e-04\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6.8601e-04\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.6821e-05\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.5561e-04\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.5041e-04\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3072e-05\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.8297e-04\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0936e-04\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.4981e-05\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.2736e-04\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.9652e-05\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0982e-04\n",
      "Epoch 344/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.0948e-04\n",
      "Epoch 345/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7315e-05\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3557e-04\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.1849e-04\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.1525e-06\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2045e-04\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 5.3859e-05\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.5325e-05\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 9.6491e-05\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5825e-05\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.5366e-05\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8425e-05\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7349e-06\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0929e-05\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0882e-05\n",
      "Epoch 359/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.1295e-06\n",
      "Epoch 360/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0296e-05\n",
      "Epoch 361/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.4678e-05\n",
      "Epoch 362/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3820e-06\n",
      "Epoch 363/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.1753e-05\n",
      "Epoch 364/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2699e-05\n",
      "Epoch 365/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.6638e-06\n",
      "Epoch 366/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.4063e-05\n",
      "Epoch 367/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.0379e-06\n",
      "Epoch 368/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8263e-06\n",
      "Epoch 369/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6903e-05\n",
      "Epoch 370/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.3292e-06\n",
      "Epoch 371/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.5479e-06\n",
      "Epoch 372/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1127e-05\n",
      "Epoch 373/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.3248e-07\n",
      "Epoch 374/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.2970e-06\n",
      "Epoch 375/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.1090e-06\n",
      "Epoch 376/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.1903e-07\n",
      "Epoch 377/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.1829e-06\n",
      "Epoch 378/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.7177e-06\n",
      "Epoch 379/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.3764e-07\n",
      "Epoch 380/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.3697e-06\n",
      "Epoch 381/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.9013e-06\n",
      "Epoch 382/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.3700e-07\n",
      "Epoch 383/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.3866e-06\n",
      "Epoch 384/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.8769e-06\n",
      "Epoch 385/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.3640e-07\n",
      "Epoch 386/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3596e-06\n",
      "Epoch 387/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9783e-06\n",
      "Epoch 388/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 2.0547e-07\n",
      "Epoch 389/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7497e-06\n",
      "Epoch 390/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3988e-06\n",
      "Epoch 391/2000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.4849e-08\n",
      "Epoch 392/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2204e-06\n",
      "Epoch 393/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1057e-06\n",
      "Epoch 394/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9052e-08\n",
      "Epoch 395/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.0057e-07\n",
      "Epoch 396/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.2342e-07\n",
      "Epoch 397/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3542e-08\n",
      "Epoch 398/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.8258e-07\n",
      "Epoch 399/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6008e-07\n",
      "Epoch 400/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.1994e-08\n",
      "Epoch 401/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.9512e-07\n",
      "Epoch 402/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.6027e-07\n",
      "Epoch 403/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.3834e-08\n",
      "Epoch 404/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3815e-07\n",
      "Epoch 405/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.2540e-07\n",
      "Epoch 406/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 9.0379e-08\n",
      "Epoch 407/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.4741e-07\n",
      "Epoch 408/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.2821e-07\n",
      "Epoch 409/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.5687e-08\n",
      "Epoch 410/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.4814e-08\n",
      "Epoch 411/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.2775e-07\n",
      "Epoch 412/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.6232e-08\n",
      "Epoch 413/2000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1272e-08\n",
      "Epoch 414/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4110e-07\n",
      "Epoch 415/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.7282e-08\n",
      "Epoch 416/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.9267e-09\n",
      "Epoch 417/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.6747e-08\n",
      "Epoch 418/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 9.0493e-08\n",
      "Epoch 419/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.9128e-09\n",
      "Epoch 420/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.4575e-08\n",
      "Epoch 421/2000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2367e-08\n",
      "Epoch 422/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.4706e-08\n",
      "Epoch 423/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.9168e-08\n",
      "Epoch 424/2000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.5347e-08\n",
      "Epoch 425/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2404e-08\n",
      "Epoch 426/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 6.5105e-09\n",
      "Epoch 427/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.6720e-08\n",
      "Epoch 428/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.8295e-08\n",
      "Epoch 429/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.1607e-09\n",
      "Epoch 430/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9412e-08\n",
      "Epoch 431/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.6711e-08\n",
      "Epoch 432/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.8720e-09\n",
      "Epoch 433/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.2340e-09\n",
      "Epoch 434/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.8117e-08\n",
      "Epoch 435/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.8016e-09\n",
      "Epoch 436/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.5088e-10\n",
      "Epoch 437/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0678e-08\n",
      "Epoch 438/2000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1636e-09\n",
      "Epoch 439/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.7335e-10\n",
      "Epoch 440/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.2416e-09\n",
      "Epoch 441/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.2684e-09\n",
      "Epoch 442/2000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 2.5524e-09\n",
      "Epoch 443/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.9500e-09\n",
      "Epoch 444/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2701e-09\n",
      "Epoch 445/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.6403e-09\n",
      "Epoch 446/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.1595e-10\n",
      "Epoch 447/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.1490e-09\n",
      "Epoch 448/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 5.0350e-09\n",
      "Epoch 449/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3679e-09\n",
      "Epoch 450/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.5670e-10\n",
      "Epoch 451/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.1240e-09\n",
      "Epoch 452/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5786e-09\n",
      "Epoch 453/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.6566e-11\n",
      "Epoch 454/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2235e-09\n",
      "Epoch 455/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.4226e-09\n",
      "Epoch 456/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.5752e-10\n",
      "Epoch 457/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.3842e-10\n",
      "Epoch 458/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.6729e-09\n",
      "Epoch 459/2000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.3120e-09\n",
      "Epoch 460/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.4051e-10\n",
      "Epoch 461/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.3300e-09\n",
      "Epoch 462/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3336e-09\n",
      "Epoch 463/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.3004e-09\n",
      "Epoch 464/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.8231e-10\n",
      "Epoch 465/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5774e-09\n",
      "Epoch 466/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.2899e-09\n",
      "Epoch 467/2000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.6601e-09\n",
      "Epoch 468/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.6880e-10\n",
      "Epoch 469/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.8767e-10\n",
      "Epoch 470/2000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.5088e-09\n",
      "Epoch 471/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8219e-09\n",
      "Epoch 472/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.0163e-10\n",
      "Epoch 473/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 2.3283e-11\n",
      "Epoch 474/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1537e-10\n",
      "Epoch 475/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0082e-10\n",
      "Epoch 476/2000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 5.2387e-11\n",
      "Epoch 477/2000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 8.4401e-11\n",
      "Epoch 478/2000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 2.9104e-10\n",
      "Epoch 479/2000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.1642e-10\n",
      "Epoch 480/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 6.9849e-11\n",
      "Epoch 481/2000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.8999e-10\n",
      "Epoch 482/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.5902e-10\n",
      "Epoch 483/2000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.7835e-11\n",
      "Epoch 484/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.8208e-11\n",
      "Epoch 485/2000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7835e-11\n",
      "Epoch 486/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.8208e-11\n",
      "Epoch 487/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7462e-11\n",
      "Epoch 488/2000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7462e-11\n",
      "Epoch 489/2000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4552e-10\n",
      "Epoch 490/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.2224e-10\n",
      "Epoch 491/2000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0000e+00\n",
      "Epoch 492/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.0768e-10\n",
      "Epoch 493/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0082e-10\n",
      "Epoch 494/2000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.1118e-11\n",
      "Epoch 495/2000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.2387e-11\n",
      "Epoch 496/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2701e-10\n",
      "Epoch 497/2000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.3865e-10\n",
      "Epoch 498/2000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2224e-10\n",
      "Epoch 499/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.4401e-11\n",
      "Epoch 500/2000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 9.8953e-11\n",
      "Epoch 501/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5134e-10\n",
      "Epoch 502/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.4738e-10\n",
      "Epoch 503/2000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.4738e-10\n",
      "Epoch 504/2000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0768e-10\n",
      "Epoch 505/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 5.8208e-12\n",
      "Epoch 506/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.9477e-11\n",
      "Epoch 507/2000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.2387e-11\n",
      "Epoch 508/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 6.4028e-11\n",
      "Epoch 509/2000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.4028e-11\n",
      "Epoch 510/2000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7462e-11\n",
      "Epoch 511/2000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7462e-11\n",
      "Epoch 512/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 4.9477e-11\n",
      "Epoch 513/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.9477e-11\n",
      "Epoch 514/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 1.7462e-11\n",
      "Epoch 515/2000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.6193e-11\n",
      "Epoch 516/2000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.2760e-11\n",
      "Epoch 517/2000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.9104e-11\n",
      "Epoch 518/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.9104e-12\n",
      "Epoch 519/2000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.9104e-12\n",
      "Epoch 520/2000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.9104e-11\n",
      "Epoch 521/2000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.9477e-11\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt8AAAELCAYAAAABTepgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAljklEQVR4nO3df5TddX3n8ec7YQwDGJJIko0TKiA0SMQyZZSwtEVQSFyLTHFt09aKB88BKT2rKLGJy0qKRaB0ldIVF9AqrFTEGiNLVUTAsq3RMGmwMfyQtEDIJCYRjKAZYBje+8f9Jt5k7k1mkpn78/k4Z86938/3+73zGT8H85rvvD+fT2QmkiRJksbfhHp3QJIkSWoXhm9JkiSpRgzfkiRJUo0YviVJkqQaMXxLkiRJNXJAvTtQS4cddlgeccQR9e6GJEmSWtiqVat+mpnTK51rq/B9xBFH0NfXV+9uSJIkqYVFxJPVzll2IkmSJNWI4VuSJEmqEcO3JEmSVCOGb0mSJKlGDN+SJElSjbTVaie1tnx1P9fc9Sgbtw3w6imdLJo/h97urnp3S5IkSXVi+B4ny1f3s2TZGgYGhwDo3zbAkmVrAAzgkiS1oGeffZYtW7YwODhY765oHHV0dDBjxgwmT568T/cbvsfJNXc9ujN47zAwOMQ1dz1q+JYkqcU8++yzbN68ma6uLjo7O4mIendJ4yAzGRgYoL+/H2CfArg13+Nk47aBiu39VdolSVLz2rJlC11dXRx00EEG7xYWERx00EF0dXWxZcuWffoMw/c4efWUzortQakkRZIktY7BwUE6Oyv/26/W09nZuc/lRTUP3xHxRESsiYgHI6KvaJsWEXdHxGPF69Sy65dExLqIeDQi5pe1n1h8zrqIuC4a7NfMRfPnUKlDSakkRZIktZYGiyIaR/sz1vV68n1aZp6QmT3F8WLgnsw8BrinOCYijgMWAnOBBcD1ETGxuOczwPnAMcXXghr2f696u7vIKucsPZEkSWpPjVJ2cjZwc/H+ZqC3rP22zHwhMx8H1gFviohZwOTMXJGZCdxSdk/D6LL0RJIkSWXqEb4T+HZErIqI84u2mZm5CaB4nVG0dwFPld27oWjrKt7v3j5MRJwfEX0R0bd169Yx/DH2ztITSZLUDCJir1/f/e539+mzn3jiCSKCO++8c7/7uXTpUg477LD9/px6qsdSg6dk5saImAHcHRGP7OHaatm1WvvwxswbgRsBenp6qlWCjIve7i4++OUHK56rthqKJElSra1YsWLn+4GBAU4//XQuvfRS3v72t+9sP+644/bps2fNmsWKFSs49thj97ufraDm4TszNxavWyLia8CbgM0RMSszNxUlJTvWbtkAHF52+2xgY9E+u0J7w+ma0lmxxntCBMtX97vmtyRJqrt58+btfP+LX/wCgNe+9rW7tJcbGhpiaGiIV7ziFXv97EmTJlX9nHZU07KTiDg4Il654z1wJvAj4A7g3OKyc4GvF+/vABZGxKSIOJLSxMqVRWnKcxExr1jl5D1l9zSURfPn0NkxcVj7UCZLlq2x9luSJO1i+ep+TrnqXo5c/I+cctW9DZEV3vve99LT08Py5cuZO3cuBx54ID/4wQ/YtGkT5513HkcddRSdnZ38+q//OpdeeikvvvjiznsrlZ0cccQRXHLJJXzqU59i9uzZTJ06lYULF7Jt27ZR9+3xxx+nt7eXyZMn88pXvpKzzjqLdevW7XLN5z73OebOnUtnZyeHHXYYp556KmvXrt15/sorr+Too4/mwAMPZObMmSxYsICf/OQno/8fagRq/eR7JvC1YnmWA4C/z8xvRcQDwO0R8T5gPfAugMxcGxG3Aw8BLwEXZeaObSMvBL4AdALfLL4azo4n2x++/YcM5a5VL+54KUmSyi1f3c+SZWt27pLdv22AJcvWANQ9LzzxxBN85CMf4WMf+xgzZ87kyCOP5Kc//SnTpk3jk5/8JFOnTuXHP/4xS5cuZevWrdxwww17/Lzbb7+dN7zhDdx4441s2LCBD33oQ3z0ox/l+uuvH3GfXnjhBd7ylrfQ0dHBTTfdxAEHHMBll13Gqaeeypo1a5g2bRr3338/73//+7n88ss5+eSTefbZZ1mxYgU///nPAbjlllv4xCc+wdVXX83cuXN5+umnuffee/nlL3+5X/97VVPT8J2Z/wH8RoX2p4G3VLnnCuCKCu19wOvHuo/jobe7i4ur1H677KAkSa3pL/7vWh7a+Oyo7lm9fhsvDr28S9vA4BAf+Yd/40sr14/4c4579WQuO2vuqL733jz99NN85zvf4YQTTtjZNnv2bP76r/965/Epp5zCwQcfzHnnncff/u3f7rEspaOjg+XLl3PAAaU4+tBDD3HbbbeNKnx//vOfZ/369fz4xz/mqKOOAuCkk07iqKOO4oYbbmDJkiWsXLmSN7zhDSxZsmTnfe94xzt2vl+5ciVnnnkmf/qnf7qz7ZxzzhlxH0arUZYabHnueClJkvZm9+C9t/Za6urq2iV4A2Qm1157LccddxydnZ10dHTwx3/8x7zwwgusX7/nXxZOO+20ncEbShM6t2zZskvJyt6sXLmS3/zN39wZvKH0C8Epp5zCP//zPwNwwgknsHr1ai6++GLuv//+YZ9/wgkn8I1vfIPLLruMlStXMjQ0xHiqx2onbWnR/Dlc/OUHhy3JsmPZwXr/KUmSJI2tfXnyfMpV91b8q3jXlE6+fMHJY9GtfTZz5sxhbddeey2XXHIJixcv5tRTT2Xq1Kk88MADXHTRRTz//PN7/LwpU6bscvyKV7yCzOTFF18c0UROgE2bNlXs18yZM3nyyScBeOtb38rnP/95rrvuOv7mb/6GQw45hHe/+91cc801O5/SP/fcc9x4441cfvnlvOpVr+LCCy9k6dKlTJw4fN7e/vLJd42446UkSdqbSgs1dHZMZNH8OXXq0a9U2lL9K1/5Cu9617u44oorOPPMM3njG9/IwQcfXLM+zZo1iy1btgxr37x5M9OmTdt5fO6557Jq1So2b97MNddcwxe+8AU+/vGPAzBhwgQuvvhiHn74YdavX88ll1zCJz7xCW666aZx6bPhu4bc8VKSJO1Jb3cXV55zPF1TOglK2eHKc45v2L+QDwwMMGnSpF3abr311pp9/5NOOolVq1bx+OOP72zr7+/ne9/7Hr/1W7817Prp06dzwQUX8Nu//ds89NBDw84ffvjhLF68mKOPPrri+bFg2UkNWXoiSZL2pre7q2kywRlnnMF1113HSSedxGtf+1puvfXWYcv8jaf3vve9XH311bztbW/j8ssvZ+LEiTt3wbzgggsAuOyyy3jmmWd485vfzGGHHcbq1av5p3/6J6666ioALrjgAqZNm8a8efM49NBDue+++3jssce4+uqrx6XPhu8acsdLSZLUSj72sY+xdetWLr30UqC0Ssh1113HWWedVZPvP2nSJL7zne/woQ99iPe9731kJm9+85tZtmzZzrKTN77xjXzqU5/itttu47nnnuM1r3kNS5cu5QMf+AAAJ598MjfddBM33HADzz//PEcffTQ33XQTvb2949LnyKzpjut11dPTk319fXXtQ7WJFFM6O3jwsjPr0CNJkrS/Hn74YV73utfVuxuqoT2NeUSsysyeSues+a6xRfPn0DFh+ISFX774knXfkiRJLc7wXWO93V0ccuDwap/BoeSaux6tQ48kSZJUK4bvOti2fbBiu0sOSpIktTbDdx2426UkSVJ7MnzXwaL5cxhe9f2rJQclSVLzaadFLNrd/oy14bsO9rTbpUsOSpLUfDo6OhgY8N/wdjEwMEBHR8c+3Wv4rpNqu11OiLD0RJKkJjNjxgz6+/vZvn27T8BbWGayfft2+vv7mTFjxj59hpvs1Mmi+XNYsmwNA4NDu7QPZbJk2RqAptndSpKkdjd58mQANm7cyOBg5YUV1Bo6OjqYOXPmzjEfLcN3newI1h++/YcM7fYb8sDgkNvNS5LUZCZPnrzPgUztw7KTOurt7uLlKn+actlBSZKk1mP4rjOXHZQkSWofhu86c9lBSZKk9mH4rjOXHZQkSWofhu8GUG3ZwUM79239SEmSJDUmw3cDWDR/Dh0Thhef/PLFl6z7liRJaiGG7wbQ293FIQcOX/VxcCit+5YkSWohhu8GsW175QX5rfuWJElqHYbvBlFtyUHrviVJklqH4btBWPctSZLU+gzfDcK6b0mSpNZn+G4g1eq+3WpekiSpNRi+G4hbzUuSJLU2w3cDcat5SZKk1laX8B0REyNidUTcWRxPi4i7I+Kx4nVq2bVLImJdRDwaEfPL2k+MiDXFuesiolJubSpuNS9JktTa6vXk+wPAw2XHi4F7MvMY4J7imIg4DlgIzAUWANdHxMTins8A5wPHFF8LatP18eVW85IkSa2r5uE7ImYDbwc+W9Z8NnBz8f5moLes/bbMfCEzHwfWAW+KiFnA5MxckZkJ3FJ2T1NzyUFJkqTWVY8n39cCHwFeLmubmZmbAIrXGUV7F/BU2XUbirau4v3u7cNExPkR0RcRfVu3bh2TH2A8ueSgJElS66pp+I6I3wW2ZOaqkd5SoS330D68MfPGzOzJzJ7p06eP8NvWl1vNS5IktaZaP/k+BXhHRDwB3AacHhFfBDYXpSQUr1uK6zcAh5fdPxvYWLTPrtDeEqotOTghwtITSZKkJlbT8J2ZSzJzdmYeQWki5b2Z+W7gDuDc4rJzga8X7+8AFkbEpIg4ktLEypVFacpzETGvWOXkPWX3NL1F8+fQ2TFxWPtQJkuWrTGAS5IkNalGWef7KuCMiHgMOKM4JjPXArcDDwHfAi7KzKHingspTdpcB/w78M1ad3q89HZ3ceU5xzOxwuqJA4ND1n5LkiQ1qSgtFtIeenp6sq+vr97dGLEjF/9jxUL2AB6/6u217o4kSZJGICJWZWZPpXON8uRbFVSr/XbNb0mSpOZk+G5grvktSZLUWgzfDcw1vyVJklqL4bvBuea3JElS6zB8NzjrviVJklqH4bvBWfctSZLUOgzfDc66b0mSpNZh+G4C1n1LkiS1BsN3E7DuW5IkqTUYvpuAdd+SJEmtwfDdBKz7liRJag2G7yZh3bckSVLzM3w3Ceu+JUmSmp/hu0lY9y1JktT8DN9NwrpvSZKk5mf4biLWfUuSJDU3w3cTqVb3Xa1dkiRJjcXw3UQWzZ9DZ8fEXdoCOO3Y6fXpkCRJkkbF8N1Eeru7eOeJXZRPu0zgq6v6nXQpSZLUBAzfTea+R7aSu7UNDA456VKSJKkJGL6bTLXJlU66lCRJanyG7yZTbXLlhAhLTyRJkhqc4bvJVJp0CTCUyZJlawzgkiRJDczw3WR6u7u48pzjmRjDd7u09luSJKmxGb6bUG93Fy/n7tMuS6z9liRJalyG7yZVrfb70M6OGvdEkiRJI2X4blKL5s+hY8Lw0pNfvviSdd+SJEkNyvDdpHq7uzjkwAOGtQ8OpXXfkiRJDcrw3cS2bR+s2G7dtyRJUmOqafiOiAMjYmVE/DAi1kbEXxTt0yLi7oh4rHidWnbPkohYFxGPRsT8svYTI2JNce66iArLf7Q4674lSZKaS62ffL8AnJ6ZvwGcACyIiHnAYuCezDwGuKc4JiKOAxYCc4EFwPURsWOR688A5wPHFF8LavhzNATrviVJkppLTcN3lvyiOOwovhI4G7i5aL8Z6C3enw3clpkvZObjwDrgTRExC5icmSsyM4Fbyu5pG9Z9S5IkNZea13xHxMSIeBDYAtydmT8AZmbmJoDidUZxeRfwVNntG4q2ruL97u2Vvt/5EdEXEX1bt24d05+lEVj3LUmS1DxqHr4zcygzTwBmU3qK/fo9XF6pjjv30F7p+92YmT2Z2TN9+vRR97fRVav7rtYuSZKk+qnbaieZuQ34LqVa7c1FKQnF65bisg3A4WW3zQY2Fu2zK7S3nUXz59DZMXGXtgBOO7b1ftGQJElqdrVe7WR6REwp3ncCbwUeAe4Azi0uOxf4evH+DmBhREyKiCMpTaxcWZSmPBcR84pVTt5Tdk9b6e3u4p0n7lpxk8BXV/U76VKSJKnB7Hf4johjI6I3Il49gstnAfdFxL8BD1Cq+b4TuAo4IyIeA84ojsnMtcDtwEPAt4CLMnOo+KwLgc9SmoT578A39/dnaVb3PTK8ln1gcMhJl5IkSQ1m+FIZexARN1BatOT9xfEfAF8EJgK/iIgFmfm9avdn5r8B3RXanwbeUuWeK4ArKrT3AXuqF28b1SZXOulSkiSpsYz2yfcC4P6y448DXwJeDdxVHKvG3GxHkiSpOYw2fM+gWPovIo4Bjgb+KjN/AtxIhafaGn9utiNJktQcRhu+nwFmFu/fCvwkM39UHAel8hPVmJvtSJIkNYdR1XxTmtR4eUTMBD5CaTLkDq8HnhijfmmU3GxHkiSp8Y32yfeHge8D76dU+/2xsnO/R2lFEtWBdd+SJEmNb1ThOzN/npnnZebxmfknmfls2bnfzsw/H/suaiSs+5YkSWp8owrfEXFAREzare3MiPhgRDjZso6s+5YkSWp8o635/jLwc+A8gIj4b8C1wAvAxIg4p9g0R3Vg3bckSVJjG23N9zzgG2XHi4D/mZmdlHab/O9j1TGNXrW672rtkiRJqq3Rhu9XAT8BiIjjKW2u87+Lc18Bjhu7rmm0Fs2fQ2fH8NUet1v3LUmS1BBGG743A0cU7xcAT2bmvxfHncDLY9Qv7YPe7i6uPOd4puy2wsnPtg+yZNkaA7gkSVKdjTZ8fwW4OiKuAf4cuKXsXDfw2Fh1TPumt7uLgycNL+UfGBxy4qUkSVKdjXbC5WLgWeCNwGeAK8vOnUhpQqbqrNoESydeSpIk1deowndmvgRcXuXcOWPSI+23V0/ppL9C0HbDHUmSpPoabdkJABFxUkR8OCKuKF5PGuuOad+54Y4kSVJjGu0mOwdHxDeAFZRKTs4rXr8XEf8YEQeNQx81Sm64I0mS1JhG++T7r4CTgT8ADszMWcCBwMKi/eqx7Z72lRvuSJIkNZ7Rhu93An+emV/JzJcBMvPlzPwKpcmY7xrrDmrfVNtYx7pvSZKk+hlt+D4UeKrKuaeAyfvXHY0V674lSZIaz2jD9w+BCyNil1RXHF9YnFcDsO5bkiSp8Yx2ne+PAt8EHomIr1Ha8XIG8HuUdr5825j2TvvFum9JkqTGMqon35l5L6WdLFdTqu++Avh94F+BM4Ghse6g9l21uu9q7ZIkSRpfo17nOzMfysyFmfnazDyoeP0jYDpw39h3Uftq0fw5dHZM3KUtgNOOnV6fDkmSJLW5fdpkR82ht7uLd57YtUtbAl9d1e+kS0mSpDowfLe4+x7ZOqxtYHDISZeSJEl1YPhucdUmVzrpUpIkqfYM3y3OSZeSJEmNY69LDUbEVkqlwnszaf+7o7G2aP4clixbw8DgrxaicdKlJElSfYxkne9PM7LwrQbU291F35PPcOv31+8cxB2TLnteM43e7q493S5JkqQxtNfwnZlLa9APjaP7Htk67LenHZMuDd+SJEm1U9Oa74g4PCLui4iHI2JtRHygaJ8WEXdHxGPF69Sye5ZExLqIeDQi5pe1nxgRa4pz1+2+5b1+xUmXkiRJjaHWEy5fAj6cma8D5gEXRcRxwGLgnsw8BrinOKY4txCYCywAro+IHbvGfAY4Hzim+FpQyx+kmVSbXHloZ0eNeyJJktTeahq+M3NTZv5r8f454GGgCzgbuLm47Gagt3h/NnBbZr6QmY8D64A3RcQsYHJmrsjMBG4pu0e7WTR/Dh0Thv9h4JcvvuRmO5IkSTVUt6UGI+IIoBv4ATAzMzdBKaADM4rLuoCnym7bULR1Fe93b6/0fc6PiL6I6Nu6dfiGM+2gt7uLQw4cXt4/OJRutiNJklRDdQnfEXEI8FXgg5n57J4urdCWe2gf3ph5Y2b2ZGbP9Ontu7zetu2DFdut+5YkSaqdmofviOigFLxvzcxlRfPmopSE4nVL0b4BOLzs9tnAxqJ9doV2VeFmO5IkSfVX69VOAvgc8HBmfrLs1B3AucX7c4Gvl7UvjIhJEXEkpYmVK4vSlOciYl7xme8pu0cVLJo/h86OicPat1v3LUmSVDMj2WRnLJ0C/AmwJiIeLNo+ClwF3B4R7wPWA+8CyMy1EXE78BCllVIuyswdWzVeCHwB6AS+WXypih3reS+9Yy3bBn5VgvKz7YMsWbZml2skSZI0PqK0WEh76Onpyb6+vnp3o65Ouepe+ivUeXdN6eRfFp9ehx5JkiS1lohYlZk9lc7VbbUT1Ycb7kiSJNWP4bvNOPFSkiSpfgzfbabSxMsATju2fZdhlCRJqhXDd5vp7e7inSfuOrEyga+u6nfVE0mSpHFm+G5D9z0yfKfPgcEhd7uUJEkaZ4bvNuSkS0mSpPowfLchJ11KkiTVh+G7DTnpUpIkqT4M323ISZeSJEn1YfhuU066lCRJqj3Dd5ty0qUkSVLtGb7bVLXJlYd2dtS4J5IkSe3D8N2mFs2fQ8eEGNb+yxdfsu5bkiRpnBi+21RvdxeHHHjAsPbBobTuW5IkaZwYvtvYtu2DFdut+5YkSRofhu825mY7kiRJtWX4bmNutiNJklRbhu82tmOznfJpl262I0mSNH4M323uvke2kru1udmOJEnS+DB8tzk325EkSaodw3ebc7MdSZKk2jF8tzk325EkSaodw3ebc7MdSZKk2jF8y812JEmSasTwLTfbkSRJqhHDtyputgOw3bpvSZKkMWX4Fr3dXVx5zvFM2W2Fk59tH2TJsjUGcEmSpDFi+BZQCuAHTxo+8dINdyRJksaO4Vs7ueGOJEnS+Kpp+I6Iv4uILRHxo7K2aRFxd0Q8VrxOLTu3JCLWRcSjETG/rP3EiFhTnLsuIoYvVK1Rc8MdSZKk8VXrJ99fABbs1rYYuCczjwHuKY6JiOOAhcDc4p7rI2LHrMDPAOcDxxRfu3+m9oEb7kiSJI2vmobvzLwfeGa35rOBm4v3NwO9Ze23ZeYLmfk4sA54U0TMAiZn5orMTOCWsnu0H9xwR5IkaXw1Qs33zMzcBFC8zijau4Cnyq7bULR1Fe93b68oIs6PiL6I6Nu6deuYdrwVueGOJEnS+GmE8F1NpTru3EN7RZl5Y2b2ZGbP9OnTx6xzrcoNdyRJksZPI4TvzUUpCcXrlqJ9A3B42XWzgY1F++wK7RoDlTbcCeC0Y/3FRZIkaX81Qvi+Azi3eH8u8PWy9oURMSkijqQ0sXJlUZryXETMK1Y5eU/ZPdpPvd1dvPPEXat4Evjqqn4nXUqSJO2nWi81+CVgBTAnIjZExPuAq4AzIuIx4IzimMxcC9wOPAR8C7goM4eKj7oQ+CylSZj/Dnyzlj9Hq7vvkeG18W62I0mStP+GL20xjjLzD6ucekuV668ArqjQ3ge8fgy7pjJutiNJkjQ+GqHsRA3GzXYkSZLGh+Fbw7jZjiRJ0vgwfGsYN9uRJEkaH4ZvVeRmO5IkSWPP8K2KrPuWJEkae4ZvVWTdtyRJ0tgzfKsi674lSZLGnuFbVVWr++637luSJGmfGL5VVbW67wBLTyRJkvaB4VtVLZo/h+FV35Bg6YkkSdI+MHyrqt7uLrLKOZcclCRJGj3Dt/aoq0rpyYQIS08kSZJGyfCtPVo0fw6dHROHtQ9lsmTZGgO4JEnSKBi+tUe93V1cec7xTIzh1d8Dg0PWfkuSJI2C4Vt71dvdxctZufrbZQclSZJGzvCtEXHZQUmSpP1n+NaIuOygJEnS/jN8a0T2tOygpSeSJEkjY/jWiFVbdtDSE0mSpJExfGvE9lR6svSOtbXujiRJUtMxfGvE9lR6sm1g0KffkiRJe2H41qhUKz0Bn35LkiTtjeFbo7Jo/pyq57YNDHLp8jU17I0kSVJzMXxrVHq7u5h6UEfV81/8/nq6L/+2JSiSJEkVHFDvDqj5XHbWXD745Qernv/Z9kEu/vKD9D35DH/Ze/zO9uWr+1l6x1q2DQzu8fOnHtTBZWfNpbe7a6y6LEmS1BAiq2wb3op6enqyr6+v3t1oCd2Xf5ufbd9ziB4vhnNJktTIImJVZvZUPGf41r5Yvrqfi7/8YNXVT1rJhICXszTZdNH8OYZ+SZK0R4bvguF7bF26fA23fn99WwTwevEpvyRJzcfwXTB8j72R1nGrMflUX5KksWf4Lhi+x8+ly9fwxe+vr3c31MR8yi9JahUtG74jYgHwN8BE4LOZedWerjd8jy8DuCRJajT1eLizp/DdtEsNRsRE4NPAGcAG4IGIuCMzH6pvz9rXX/YeT89rpu21DKXafwSWsEiSpLH2s+2DLPqHHwI0xF9Xm/bJd0ScDCzNzPnF8RKAzLyy2j0++W5uy1f3c81dj9K/bYAAJ3pKkqQR65rSyb8sPr0m36sln3wDXcBTZccbgJN2vygizgfOB/i1X/u12vRM46K3u6suv7H6RF6SpOa3cdtAvbsANHf4jgptwx6GZuaNwI1QevI93p1S66lH6DfwS5I0tl49pbPeXQCaO3xvAA4vO54NbKxTX6QxVavAb8iXJLWDjonBovlz6t0NoLnD9wPAMRFxJNAPLAT+qL5dkppLvUp5ducvAZKk8dJoS9k2bfjOzJci4s+AuygtNfh3mbm2zt2StA8a5ZcASZLGW9OGb4DM/AbwjXr3Q5IkSRqJCfXugCRJktQuDN+SJElSjRi+JUmSpBoxfEuSJEk10rTby++LiNgKPFnjb3sY8NMaf0+NL8e09TimrccxbT2Oaetp5TF9TWZOr3SircJ3PUREX2b21LsfGjuOaetxTFuPY9p6HNPW065jatmJJEmSVCOGb0mSJKlGDN/j78Z6d0BjzjFtPY5p63FMW49j2nrackyt+ZYkSZJqxCffkiRJUo0YviVJkqQaMXyPk4hYEBGPRsS6iFhc7/5o5CLi7yJiS0T8qKxtWkTcHRGPFa9Ty84tKcb50YiYX59eq5qIODwi7ouIhyNibUR8oGh3TJtURBwYESsj4ofFmP5F0e6YNrmImBgRqyPizuLYMW1yEfFERKyJiAcjoq9oa+txNXyPg4iYCHwaeBtwHPCHEXFcfXulUfgCsGC3tsXAPZl5DHBPcUwxrguBucU91xfjr8bxEvDhzHwdMA+4qBg3x7R5vQCcnpm/AZwALIiIeTimreADwMNlx45pazgtM08oW9O7rcfV8D0+3gSsy8z/yMwXgduAs+vcJ41QZt4PPLNb89nAzcX7m4HesvbbMvOFzHwcWEdp/NUgMnNTZv5r8f45Sv+wd+GYNq0s+UVx2FF8JY5pU4uI2cDbgc+WNTumramtx9XwPT66gKfKjjcUbWpeMzNzE5TCHDCjaHesm0hEHAF0Az/AMW1qRXnCg8AW4O7MdEyb37XAR4CXy9oc0+aXwLcjYlVEnF+0tfW4HlDvDrSoqNDmmo6tybFuEhFxCPBV4IOZ+WxEpaErXVqhzTFtMJk5BJwQEVOAr0XE6/dwuWPa4CLid4EtmbkqIt48klsqtDmmjemUzNwYETOAuyPikT1c2xbj6pPv8bEBOLzseDawsU590djYHBGzAIrXLUW7Y90EIqKDUvC+NTOXFc2OaQvIzG3AdynVhzqmzesU4B0R8QSlUs3TI+KLOKZNLzM3Fq9bgK9RKiNp63E1fI+PB4BjIuLIiHgFpckDd9S5T9o/dwDnFu/PBb5e1r4wIiZFxJHAMcDKOvRPVUTpEffngIcz85NlpxzTJhUR04sn3kREJ/BW4BEc06aVmUsyc3ZmHkHp38x7M/PdOKZNLSIOjohX7ngPnAn8iDYfV8tOxkFmvhQRfwbcBUwE/i4z19a5WxqhiPgS8GbgsIjYAFwGXAXcHhHvA9YD7wLIzLURcTvwEKVVNS4q/hyuxnEK8CfAmqJGGOCjOKbNbBZwc7EKwgTg9sy8MyJW4Ji2Gv87bW4zKZWFQSlz/n1mfisiHqCNx9Xt5SVJkqQasexEkiRJqhHDtyRJklQjhm9JkiSpRgzfkiRJUo0YviVJkqQaMXxLUouIiKURkVW+3l2H/mSx7KokqeA635LUWn5OabfH3a2rdUckScMZviWptbyUmd+vdyckSZVZdiJJbSIijihKQf4oIv5PRDwXEVsi4rIK154eET+IiOcjYnNEXB8Rh+x2zasi4oaI2FRc92hEfHC3j5oYEZ+IiK3F9/p0REwaz59TkhqZT74lqcVExLD/b8/Ml8oOrwHuBP4r8DvAZRHx08z8dHH/ccC3gLuBdwKHU9rm+yiKkpaI6AS+C8wA/gJ4BDi6+Cr3YeBe4N3AG4ArgSeBv9r/n1SSmo/by0tSi4iIpcCwp9iFI4vXx4G7M/PMsvtuAv4LcHhmvhwRtwEnAsdm5lBxze8DXwb+c2auiIgLgM8Av5mZD1bpTwL/LzN/p6xtOfCfMnPePv+gktTELDuRpNbyc+CNFb42ll3ztd3uWQa8GphdHL8J+NqO4F34KvAS8FvF8enA6mrBu8y3dzt+qOz7SFLbsexEklrLS5nZV+lEROx4u2W3UzuOZwHri9fN5Rdk5lBEPA1MK5peBWwaQX+27Xb8InDgCO6TpJbkk29Jaj8zqhxvKnvd5ZqImEgpcD9TND1NKaRLkkbB8C1J7ef3djs+h1Lg3lAc/wD4vSJwl19zAPDPxfE9QHdEvGE8OypJrcayE0lqLQdERKXJjE+VvZ8bETdQquP+HeB9wAcy8+Xi/F8Cq4HlEfEZSjXaVwN3ZeaK4ppbgIuAbxcTPR+lNKnz1zNz8Rj/TJLUMgzfktRaDgVWVGj/H8AXi/cfAX6XUvh+Hvg48L92XJiZayPibcAnKE3GfBb4UnHfjmuej4jTKS1BeDkwGXgCuH5sfxxJai0uNShJbSIijqC01OBZmXlnnbsjSW3Jmm9JkiSpRgzfkiRJUo1YdiJJkiTViE++JUmSpBoxfEuSJEk1YviWJEmSasTwLUmSJNWI4VuSJEmqkf8PHA83L6cyEUgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "runModel(ConvLSTM, X, y, learning_rate=0.001, epochs=2000, patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictValue(model, X_):\n",
    "    X = X_.reshape((1, n_seq, 1, n_steps, n_features))\n",
    "    yhat_ = model.predict(X, verbose=0)\n",
    "    yhat = yhat_.flatten()[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM: 101.327\n"
     ]
    }
   ],
   "source": [
    "X_ = np.array([60, 70, 80, 90])\n",
    "print(f\"ConvLSTM: {predictValue(ConvLSTM, X_):5.3f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "183983f8581d242f392f04aa55828dc2781ebbbbdf8bf6ac72073cf044539615"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('tf': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
